{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d657e8-2d52-4ace-8001-6c4f2a0620cc",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ee3070-fce3-4648-a95e-5d03b9a923cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "path_to_cv_module = r'c:\\users\\srish\\appdata\\local\\programs\\python\\python39\\lib\\site-packages'\n",
    "sys.path.append(path_to_cv_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68585572-5388-4f3a-9715-6ba82961d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b4f2433-5e98-4d8c-90fa-3ebb0f48af51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mp4', 'json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = r'deepfake-detection-challenge\\train_sample_videos'\n",
    "types_ = []\n",
    "\n",
    "for file in os.listdir(files):\n",
    "    types = file.split('.')[1]\n",
    "    if types not in types_:\n",
    "        types_.append(types)\n",
    "types_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "122b1fe7-678b-45ba-81e3-bc853f9b45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT = False\n",
    "\n",
    "files = r'deepfake-detection-challenge\\train_sample_videos'\n",
    "frames = r'frames'\n",
    "def get_frames(files, frame_path, ext):\n",
    "    count = 0\n",
    "    for f in tqdm(os.listdir(files)):\n",
    "        if 'mp4' in f:\n",
    "            try:\n",
    "                path = os.path.join(files, f)\n",
    "                cap = cv2.VideoCapture(path)\n",
    "                n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "                \n",
    "                count += 1\n",
    "                # print(n_frames, fps)    # 300, 29 for all videos; all videos are ~10s long\n",
    "                \n",
    "                framess = os.path.join(frame_path, f.split('.')[0])\n",
    "                n = 0\n",
    "                while True:\n",
    "                    ret, frame = cap.read()\n",
    "                    cv2.imwrite('{}_{}.{}'.format(framess, str(n).zfill(len(str(n_frames))), ext), frame)\n",
    "                    n += 1\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "        print(path)\n",
    "        print(count)\n",
    "if EXTRACT:\n",
    "    get_frames(files, frames, 'jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ef8d836-8d53-4f7b-b143-19eb1e422f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3166ba8-f624-4f28-ad48-ca71278df1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'metadata.json'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json = [file for file in os.listdir(files) if file.endswith('json')][0]\n",
    "json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4709343e-fc30-4871-8e60-420764b0e197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aagfhgtpmv.mp4</th>\n",
       "      <th>aapnvogymq.mp4</th>\n",
       "      <th>abarnvbtwb.mp4</th>\n",
       "      <th>abofeumbvv.mp4</th>\n",
       "      <th>abqwwspghj.mp4</th>\n",
       "      <th>acifjvzvpm.mp4</th>\n",
       "      <th>acqfdwsrhi.mp4</th>\n",
       "      <th>acxnxvbsxk.mp4</th>\n",
       "      <th>acxwigylke.mp4</th>\n",
       "      <th>aczrgyricp.mp4</th>\n",
       "      <th>...</th>\n",
       "      <th>esnntzzajv.mp4</th>\n",
       "      <th>esxrvsgpvb.mp4</th>\n",
       "      <th>esyhwdfnxs.mp4</th>\n",
       "      <th>esyrimvzsa.mp4</th>\n",
       "      <th>etdcqxabww.mp4</th>\n",
       "      <th>etejaapnxh.mp4</th>\n",
       "      <th>etmcruaihe.mp4</th>\n",
       "      <th>etohcvnzbj.mp4</th>\n",
       "      <th>eudeqjhdfd.mp4</th>\n",
       "      <th>eukvucdetx.mp4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>REAL</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>REAL</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>vudstovrck.mp4</td>\n",
       "      <td>jdubbvfswz.mp4</td>\n",
       "      <td>None</td>\n",
       "      <td>atvmxvwyns.mp4</td>\n",
       "      <td>qzimuostzz.mp4</td>\n",
       "      <td>kbvibjhfzo.mp4</td>\n",
       "      <td>ccfoszqabv.mp4</td>\n",
       "      <td>fjlyaizcwc.mp4</td>\n",
       "      <td>ffcwhpnpuw.mp4</td>\n",
       "      <td>slwkmefgde.mp4</td>\n",
       "      <td>...</td>\n",
       "      <td>ybetenmsye.mp4</td>\n",
       "      <td>gomwfvijiv.mp4</td>\n",
       "      <td>qeumxirsme.mp4</td>\n",
       "      <td>qzklcjjxdq.mp4</td>\n",
       "      <td>gipbyjfxfp.mp4</td>\n",
       "      <td>wtreibcmgm.mp4</td>\n",
       "      <td>afoovlsmtx.mp4</td>\n",
       "      <td>bdnaqemxmr.mp4</td>\n",
       "      <td>None</td>\n",
       "      <td>gjypopglvi.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          aagfhgtpmv.mp4  aapnvogymq.mp4 abarnvbtwb.mp4  abofeumbvv.mp4  \\\n",
       "label               FAKE            FAKE           REAL            FAKE   \n",
       "split              train           train          train           train   \n",
       "original  vudstovrck.mp4  jdubbvfswz.mp4           None  atvmxvwyns.mp4   \n",
       "\n",
       "          abqwwspghj.mp4  acifjvzvpm.mp4  acqfdwsrhi.mp4  acxnxvbsxk.mp4  \\\n",
       "label               FAKE            FAKE            FAKE            FAKE   \n",
       "split              train           train           train           train   \n",
       "original  qzimuostzz.mp4  kbvibjhfzo.mp4  ccfoszqabv.mp4  fjlyaizcwc.mp4   \n",
       "\n",
       "          acxwigylke.mp4  aczrgyricp.mp4  ...  esnntzzajv.mp4  esxrvsgpvb.mp4  \\\n",
       "label               FAKE            FAKE  ...            FAKE            FAKE   \n",
       "split              train           train  ...           train           train   \n",
       "original  ffcwhpnpuw.mp4  slwkmefgde.mp4  ...  ybetenmsye.mp4  gomwfvijiv.mp4   \n",
       "\n",
       "          esyhwdfnxs.mp4  esyrimvzsa.mp4  etdcqxabww.mp4  etejaapnxh.mp4  \\\n",
       "label               FAKE            FAKE            FAKE            FAKE   \n",
       "split              train           train           train           train   \n",
       "original  qeumxirsme.mp4  qzklcjjxdq.mp4  gipbyjfxfp.mp4  wtreibcmgm.mp4   \n",
       "\n",
       "          etmcruaihe.mp4  etohcvnzbj.mp4 eudeqjhdfd.mp4  eukvucdetx.mp4  \n",
       "label               FAKE            FAKE           REAL            FAKE  \n",
       "split              train           train          train           train  \n",
       "original  afoovlsmtx.mp4  bdnaqemxmr.mp4           None  gjypopglvi.mp4  \n",
       "\n",
       "[3 rows x 400 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('deepfake-detection-challenge/train_sample_videos/metadata.json')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd1d86e4-0c5b-4531-9586-64294c1aa4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aagfhgtpmv.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>vudstovrck.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aapnvogymq.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>jdubbvfswz.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abarnvbtwb.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abofeumbvv.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>atvmxvwyns.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abqwwspghj.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>qzimuostzz.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label  split        original\n",
       "aagfhgtpmv.mp4  FAKE  train  vudstovrck.mp4\n",
       "aapnvogymq.mp4  FAKE  train  jdubbvfswz.mp4\n",
       "abarnvbtwb.mp4  REAL  train            None\n",
       "abofeumbvv.mp4  FAKE  train  atvmxvwyns.mp4\n",
       "abqwwspghj.mp4  FAKE  train  qzimuostzz.mp4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.transpose()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5b967e6-ae8d-4ba3-9a27-0a71093bc8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3af39189-a17f-414e-a4ad-1a1f63693f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = 'split', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0236a57-2e57-4664-98a9-200d0659789d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aagfhgtpmv.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>vudstovrck.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aapnvogymq.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>jdubbvfswz.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abarnvbtwb.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abofeumbvv.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>atvmxvwyns.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abqwwspghj.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>qzimuostzz.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label        original\n",
       "aagfhgtpmv.mp4  FAKE  vudstovrck.mp4\n",
       "aapnvogymq.mp4  FAKE  jdubbvfswz.mp4\n",
       "abarnvbtwb.mp4  REAL            None\n",
       "abofeumbvv.mp4  FAKE  atvmxvwyns.mp4\n",
       "abqwwspghj.mp4  FAKE  qzimuostzz.mp4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77c9df43-ca16-4608-9a8d-3aeb3477cb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.groupby('label')['label'].count().plot(figsize=(15, 5), kind='bar', title='Distribution of Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a6b4d0c-bd3f-481a-8cb1-911db0e513ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "FAKE    323\n",
       "REAL     77\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution = data.groupby('label')['label'].count()\n",
    "distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "525c28b6-a942-404e-a2cd-9bea4d2f45be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(data['label']).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "969a2419-1757-4729-917f-3202728ffedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba7b7f1-4a21-431a-8eba-ef4156585204",
   "metadata": {},
   "source": [
    "# GETTING IMAGES AND LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d64e519e-9316-479d-8cbc-75d5d2764257",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for row in data.index:\n",
    "    index_list.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23736bef-9c37-49d1-b86b-9780a52faaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6210a16f-87a7-49cc-8e7b-5837128138e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aagfhgtpmv'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(index_list)):\n",
    "    index_list[i] = index_list[i].split('.')[0]\n",
    "index_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711f73fe-e941-48f3-a1c7-f77b2d42079c",
   "metadata": {},
   "source": [
    "images_path = 'frames'\n",
    "images = os.listdir(images_path)\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd92b45-c4ee-461d-947c-afc242194521",
   "metadata": {},
   "source": [
    "images[0].split('_')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1012976d-3825-4e3b-a389-4919b9a1d7a1",
   "metadata": {},
   "source": [
    "data.loc[index_list[0]+'.mp4', 'label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeab30f-7db4-48dd-b7df-5191cd340c6b",
   "metadata": {},
   "source": [
    "data.loc[images[0].split('_')[0]+'.mp4', 'label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e40a9a4-f7bf-4140-ab09-a2a20a9d631c",
   "metadata": {},
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6786a3a-58e2-4cae-b9ff-08f5ad4d3887",
   "metadata": {},
   "source": [
    "index_list[1], index_list[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fe24b1-fcce-4e67-a1fb-f38d5e189ea4",
   "metadata": {},
   "source": [
    "images[300], images[600]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e5e91a-aad6-4f3f-bc7a-4555f6918afe",
   "metadata": {},
   "source": [
    "# TRAIN, VALIDATION, TEST SPLIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b634bc-0af3-4135-9bd5-fcfe385d5aaf",
   "metadata": {},
   "source": [
    "from torch.utils.data import random_split\n",
    "MANUAL_SEED = torch.Generator().manual_seed(42)\n",
    "train, test = random_split(images, [71984, 47990], generator = MANUAL_SEED)    # 60, 40 split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850092a-c647-4b72-9e65-f4e644417cb3",
   "metadata": {},
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4503839a-5c7a-4ceb-b26f-098bac373b1b",
   "metadata": {},
   "source": [
    "validation, test = random_split(test, [23995, 23995])   #50, 50 split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3531ad12-f151-4ebb-8c0b-d8eefb1751fa",
   "metadata": {},
   "source": [
    "len(validation), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ae19b1-35c8-46d1-8920-02257d147a09",
   "metadata": {},
   "source": [
    "train[0], test[0], validation[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047a23cc-1f90-4734-bac3-ccd0fb011a0b",
   "metadata": {},
   "source": [
    "os.path.join('frames', train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d4d3e-d276-4796-97ea-56e00fd1606c",
   "metadata": {},
   "source": [
    "data.loc[train[0].split('_')[0]+'.mp4']['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d39e82-a373-47a0-80e4-9afa5aa3d82d",
   "metadata": {},
   "source": [
    "#img = cv2.imread(os.path.join('frames', train[0]), cv2.IMREAD_COLOR)\n",
    "#cv2.imshow('color image', img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "img = plt.imread(os.path.join('frames', train[0]))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d592af6-5f9c-4a06-8c09-4edb37a84dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = plt.imread(os.path.join('frames', images[0]))\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffdb087-c9cc-4213-abcf-0cafc77bbd76",
   "metadata": {},
   "source": [
    "### MAKING REAL FAKE TRAIN TEST VALIDATION FOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4b91a30-35a1-47b6-b2f7-05c8d89f82a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "MOVE = False\n",
    "def move_images(frames_directory, dataset_directory, split_info):\n",
    "    if not os.path.exists(frames_directory):\n",
    "        print(f\"Frames directory '{frames_directory}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    for category in split_info:\n",
    "        for label in split_info[category]:\n",
    "            directory = os.path.join(dataset_directory, category, label)\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "\n",
    "    for root, _, files in os.walk(frames_directory):\n",
    "        for file in files:\n",
    "            if file in test:\n",
    "                split = 'test'\n",
    "            elif file in train:\n",
    "                split = 'train'\n",
    "            else:\n",
    "                split = 'validation'\n",
    "            label = 'REAL' if data.loc[file.split('_')[0]+'.mp4']['label'] == 'REAL' else 'FAKE'\n",
    "            source_path = os.path.join(root, file)\n",
    "            destination_directory = os.path.join(dataset_directory, split, label)\n",
    "            destination_path = os.path.join(destination_directory, file)\n",
    "\n",
    "            shutil.move(source_path, destination_path)\n",
    "            print(f\"Moved '{file}' to '{destination_path}'\")\n",
    "\n",
    "split_info = {\n",
    "    'train': ['REAL', 'FAKE'],\n",
    "    'test': ['REAL', 'FAKE'],\n",
    "    'validation': ['REAL', 'FAKE']\n",
    "}\n",
    "\n",
    "if MOVE:\n",
    "    move_images('frames', 'Dataset', split_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f34995-acf1-4737-92f0-42950b121086",
   "metadata": {},
   "source": [
    "# DATA TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c6e4fdc-8007-46eb-931e-917ce6357118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0678167-f9d1-4227-b8a0-ad1afb32188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae860731-0b97-4d7a-bd64-7941533cc0b5",
   "metadata": {},
   "source": [
    "image_path = 'Dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d567701a-76aa-4ee0-b2c5-b6ed2f288a7a",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "def plot_transformed_images(image_paths, transform, n=3, seed=42):\n",
    "    random.seed(seed)\n",
    "    random_image_paths = random.sample(image_paths, k=n)\n",
    "    for image_path in random_image_paths:\n",
    "        with Image.open(image_path) as f:\n",
    "            fig, ax = plt.subplots(1, 2)\n",
    "            ax[0].imshow(f) \n",
    "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
    "            ax[0].axis(\"off\")\n",
    "            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
    "            transformed_image = transform(f).permute(1, 2, 0) \n",
    "            ax[1].imshow(transformed_image) \n",
    "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
    "            ax[1].axis(\"off\")\n",
    "\n",
    "            fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n",
    "\n",
    "image_path_list = list(image_path.glob(\"*/*.jpg\"))\n",
    "plot_transformed_images(image_path_list, \n",
    "                        transform=data_transform, \n",
    "                        n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e114207-1f44-487f-88ff-ce81e11c9b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'Dataset/Train'\n",
    "test_dir = 'Dataset/Test'\n",
    "validation_dir = 'Dataset/Validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a6c2a22-70b4-42f4-af2f-d83ad10270c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "train_data = datasets.ImageFolder(root = train_dir, # target folder of images\n",
    "                                  transform = data_transform, # transforms to perform on data (images)\n",
    "                                  target_transform = None) # transforms to perform on labels (if necessary)\n",
    "\n",
    "test_data = datasets.ImageFolder(root = test_dir, \n",
    "                                 transform = data_transform)\n",
    "\n",
    "validation_data = datasets.ImageFolder(root = validation_dir, \n",
    "                                 transform = data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "debc5dc3-de6c-486f-b318-28e492ca648a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FAKE', 'REAL']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb69ebe0-d208-430a-994c-351805d0e71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FAKE': 0, 'REAL': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = train_data.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcb4d8ee-a57d-47c0-940b-ec998cc7cb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71984, 23995, 23995)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data), len(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fb89f3c-994e-407c-bd32-c107064b1a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image tensor:\n",
      "tensor([[[0.7882, 0.7882, 0.7882,  ..., 0.8039, 0.7961, 0.7961],\n",
      "         [0.7922, 0.7922, 0.7882,  ..., 0.8078, 0.7961, 0.7961],\n",
      "         [0.7961, 0.7961, 0.7882,  ..., 0.8118, 0.8000, 0.7961],\n",
      "         ...,\n",
      "         [0.7569, 0.7647, 0.8039,  ..., 0.8000, 0.8157, 0.8392],\n",
      "         [0.7569, 0.7608, 0.8078,  ..., 0.7961, 0.8118, 0.8353],\n",
      "         [0.7529, 0.7608, 0.8078,  ..., 0.7922, 0.8078, 0.8314]],\n",
      "\n",
      "        [[0.8314, 0.8314, 0.8314,  ..., 0.8235, 0.8275, 0.8314],\n",
      "         [0.8314, 0.8314, 0.8314,  ..., 0.8235, 0.8275, 0.8314],\n",
      "         [0.8314, 0.8314, 0.8314,  ..., 0.8235, 0.8275, 0.8314],\n",
      "         ...,\n",
      "         [0.8353, 0.8392, 0.8824,  ..., 0.8196, 0.8588, 0.9020],\n",
      "         [0.8353, 0.8392, 0.8863,  ..., 0.8235, 0.8588, 0.9020],\n",
      "         [0.8392, 0.8431, 0.8863,  ..., 0.8235, 0.8588, 0.9059]],\n",
      "\n",
      "        [[0.7686, 0.7686, 0.7686,  ..., 0.7373, 0.7333, 0.7255],\n",
      "         [0.7686, 0.7686, 0.7686,  ..., 0.7373, 0.7333, 0.7255],\n",
      "         [0.7647, 0.7647, 0.7686,  ..., 0.7412, 0.7373, 0.7294],\n",
      "         ...,\n",
      "         [0.8039, 0.8314, 0.9333,  ..., 0.7647, 0.8431, 0.9216],\n",
      "         [0.8196, 0.8431, 0.9412,  ..., 0.7686, 0.8471, 0.9255],\n",
      "         [0.8275, 0.8471, 0.9451,  ..., 0.7686, 0.8471, 0.9255]]])\n",
      "Image shape: torch.Size([3, 224, 224])\n",
      "Image datatype: torch.float32\n",
      "Image label: 0\n",
      "Label datatype: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "img, label = train_data[0][0], train_data[0][1]\n",
    "print(f\"Image tensor:\\n{img}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image datatype: {img.dtype}\")\n",
    "print(f\"Image label: {label}\")\n",
    "print(f\"Label datatype: {type(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07bec4d9-212f-4f49-a38f-f515dc2843a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x21f89197340>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x21f89197d90>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x21f89197ac0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn train and test Datasets into DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(dataset = train_data, \n",
    "                              batch_size = 32, # how many samples per batch?\n",
    "                              num_workers = os.cpu_count(), # how many subprocesses to use for data loading? (higher = more)\n",
    "                              shuffle = True) # shuffle the data?\n",
    "\n",
    "test_dataloader = DataLoader(dataset = test_data, \n",
    "                             batch_size = 32, \n",
    "                             num_workers = os.cpu_count(), \n",
    "                             shuffle = False) # don't usually need to shuffle testing data\n",
    "\n",
    "validation_dataloader = DataLoader(dataset = validation_data, \n",
    "                             batch_size = 32, \n",
    "                             num_workers = os.cpu_count(), \n",
    "                             shuffle = False)\n",
    "train_dataloader, test_dataloader, validation_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d134e6a7-fd2e-48dd-9d04-b7a6de592ecd",
   "metadata": {},
   "source": [
    "# MODEL TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d27eb-7466-4355-b9d8-34f42cdbd0e7",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b042d782-81ed-4e6a-bc4f-843cbb7eeb5c",
   "metadata": {},
   "source": [
    "path = os.walk('frames')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c83e9f2-0906-4c83-b704-32abe723cae6",
   "metadata": {},
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ba6fa1-091b-4244-9a6f-e9a332a645ba",
   "metadata": {},
   "source": [
    "list(path)[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da37b504-db10-4c2a-ba9a-7dabc1eee41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyVGG(\n",
       "  (conv_block_1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=28090, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture copying TinyVGG from: \n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3, # how big is the square that's going over the image?\n",
    "                      stride=1, # default\n",
    "                      padding=0), # options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # default stride value is same as kernel_size\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # Where did this in_features shape come from? \n",
    "            # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
    "            nn.Linear(in_features=hidden_units*53*53,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv_block_1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.conv_block_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "        # return self.classifier(self.conv_block_2(self.conv_block_1(x))) # <- leverage the benefits of operator fusion\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(42)\n",
    "model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB) \n",
    "                  hidden_units=10, \n",
    "                  output_shape=len(train_data.classes)).to(device)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fc84aae-7489-4102-9695-b93444c89845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single image shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "Output logits:\n",
      "tensor([[0.0326, 0.0052]], device='cuda:0')\n",
      "\n",
      "Output prediction probabilities:\n",
      "tensor([[0.5068, 0.4932]], device='cuda:0')\n",
      "\n",
      "Output prediction label:\n",
      "tensor([0], device='cuda:0')\n",
      "\n",
      "Actual label:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 1. Get a batch of images and labels from the DataLoader\n",
    "img_batch, label_batch = next(iter(train_dataloader))\n",
    "\n",
    "# 2. Get a single image from the batch and unsqueeze the image so its shape fits the model\n",
    "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
    "print(f\"Single image shape: {img_single.shape}\\n\")\n",
    "\n",
    "# 3. Perform a forward pass on a single image\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    pred = model_0(img_single.to(device))\n",
    "    \n",
    "# 4. Print out what's happening and convert model logits -> pred probs -> pred label\n",
    "print(f\"Output logits:\\n{pred}\\n\")\n",
    "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
    "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
    "print(f\"Actual label:\\n{label_single}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cecf310-decc-47c0-b6df-45ae25bb93b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TinyVGG                                  [1, 2]                    --\n",
       "â”œâ”€Sequential: 1-1                        [1, 10, 110, 110]         --\n",
       "â”‚    â””â”€Conv2d: 2-1                       [1, 10, 222, 222]         280\n",
       "â”‚    â””â”€ReLU: 2-2                         [1, 10, 222, 222]         --\n",
       "â”‚    â””â”€Conv2d: 2-3                       [1, 10, 220, 220]         910\n",
       "â”‚    â””â”€ReLU: 2-4                         [1, 10, 220, 220]         --\n",
       "â”‚    â””â”€MaxPool2d: 2-5                    [1, 10, 110, 110]         --\n",
       "â”œâ”€Sequential: 1-2                        [1, 10, 53, 53]           --\n",
       "â”‚    â””â”€Conv2d: 2-6                       [1, 10, 108, 108]         910\n",
       "â”‚    â””â”€ReLU: 2-7                         [1, 10, 108, 108]         --\n",
       "â”‚    â””â”€Conv2d: 2-8                       [1, 10, 106, 106]         910\n",
       "â”‚    â””â”€ReLU: 2-9                         [1, 10, 106, 106]         --\n",
       "â”‚    â””â”€MaxPool2d: 2-10                   [1, 10, 53, 53]           --\n",
       "â”œâ”€Sequential: 1-3                        [1, 2]                    --\n",
       "â”‚    â””â”€Flatten: 2-11                     [1, 28090]                --\n",
       "â”‚    â””â”€Linear: 2-12                      [1, 2]                    56,182\n",
       "==========================================================================================\n",
       "Total params: 59,192\n",
       "Trainable params: 59,192\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 78.74\n",
       "==========================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 9.65\n",
       "Params size (MB): 0.24\n",
       "Estimated Total Size (MB): 10.49\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "from torchinfo import summary\n",
    "summary(model_0, input_size=[1, 3, 224, 224]) # do a test pass through of an example input size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3c9a900-f7d4-476b-bbcd-832352c5d89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer):\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    # Loop through data loader data batches\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Send data to target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item() \n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate and accumulate accuracy metric across all batches\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0388ce3-1546-45ae-94f2-62a1dc3bebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module):\n",
    "    # Put model in eval mode\n",
    "    model.eval() \n",
    "    \n",
    "    # Setup test loss and test accuracy values\n",
    "    val_loss, val_acc = 0, 0\n",
    "    \n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # Send data to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "    \n",
    "            # 1. Forward pass\n",
    "            val_pred_logits = model(X)\n",
    "\n",
    "            # 2. Calculate and accumulate loss\n",
    "            loss = loss_fn(val_pred_logits, y)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Calculate and accumulate accuracy\n",
    "            val_pred_labels = val_pred_logits.argmax(dim=1)\n",
    "            val_acc += ((val_pred_labels == y).sum().item()/len(val_pred_labels))\n",
    "            \n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    val_loss = val_loss / len(dataloader)\n",
    "    val_acc = val_acc / len(dataloader)\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "085604c6-80b5-4916-b5b1-e48cbd92b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. Take in various parameters required for training and test steps\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          validation_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5):\n",
    "    \n",
    "    # 2. Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": []\n",
    "    }\n",
    "    \n",
    "    # 3. Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        val_loss, val_acc = validation_step(model=model,\n",
    "            dataloader=validation_dataloader,\n",
    "            loss_fn=loss_fn)\n",
    "        \n",
    "        # 4. Print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"val_loss: {val_loss:.4f} | \"\n",
    "            f\"val_acc: {val_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # 5. Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"val_loss\"].append(val_loss)\n",
    "        results[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    # 6. Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4268df91-98d8-4d1b-a464-bab8255b0fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f06eb62da8f4b2a919f149e45af5c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.3890 | train_acc: 0.8239 | val_loss: 0.3425 | val_acc: 0.8347\n",
      "Epoch: 2 | train_loss: 0.3048 | train_acc: 0.8583 | val_loss: 0.2963 | val_acc: 0.8632\n",
      "Epoch: 3 | train_loss: 0.2718 | train_acc: 0.8718 | val_loss: 0.2871 | val_acc: 0.8699\n",
      "Epoch: 4 | train_loss: 0.2501 | train_acc: 0.8823 | val_loss: 0.2642 | val_acc: 0.8778\n",
      "Epoch: 5 | train_loss: 0.2313 | train_acc: 0.8919 | val_loss: 0.2461 | val_acc: 0.8886\n",
      "Total training time: 25096.884 seconds\n"
     ]
    }
   ],
   "source": [
    "# Set number of epochs\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Recreate an instance of TinyVGG\n",
    "model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB) \n",
    "                  hidden_units=10, \n",
    "                  output_shape=len(train_data.classes)).to(device)\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# Train model_0 \n",
    "model_0_results = train(model=model_0, \n",
    "                        train_dataloader=train_dataloader,\n",
    "                        validation_dataloader=validation_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn, \n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "334fcab8-aa54-4bd1-8ff1-dc7f1261467f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models\\deepfake_model_0.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create models directory\n",
    "MODEL_PATH = Path('models')\n",
    "MODEL_PATH.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "# Create model save path\n",
    "MODEL_NAME = 'deepfake_model_0.pth'\n",
    "MODEL_SAVE_PATH = MODEL_PATH/MODEL_NAME\n",
    "\n",
    "# Save the model state dict\n",
    "print(f'Saving model to: {MODEL_SAVE_PATH}')\n",
    "torch.save(obj = model_0.state_dict(), f = MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6203aef-836d-41bb-8b58-41cf59c9435e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyVGG(\n",
       "  (conv_block_1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=28090, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TinyVGG(input_shape = 3,\n",
    "                  hidden_units = 10, \n",
    "                  output_shape = len(train_data.classes))\n",
    "# optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "# checkpoint = torch.load(MODEL_SAVE_PATH)\n",
    "model.load_state_dict(torch.load(f = MODEL_SAVE_PATH))\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97dde50b-e799-40e4-9431-ffa7fc340623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv_block_1.0.weight',\n",
       "              tensor([[[[ 1.1837e-01,  2.9026e-01,  2.6288e-01],\n",
       "                        [-1.4079e-01,  2.6763e-02,  1.5631e-01],\n",
       "                        [ 1.7408e-02,  7.9755e-02, -1.3270e-01]],\n",
       "              \n",
       "                       [[-5.3196e-02,  1.3283e-01,  9.5511e-03],\n",
       "                        [-6.4856e-02, -1.6480e-01, -4.3972e-02],\n",
       "                        [-1.9400e-01, -2.4632e-01,  1.0945e-01]],\n",
       "              \n",
       "                       [[-2.2386e-01,  6.4286e-02, -7.8982e-02],\n",
       "                        [-7.9667e-02, -5.5558e-02, -6.5885e-02],\n",
       "                        [ 4.8525e-02, -8.7299e-02, -7.2351e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5011e-01, -1.9989e-02,  8.6248e-02],\n",
       "                        [ 1.0760e-01,  4.8993e-02,  4.2714e-02],\n",
       "                        [ 2.6001e-01,  1.0274e-01, -3.7092e-02]],\n",
       "              \n",
       "                       [[ 2.4738e-01,  3.6498e-02, -9.9289e-02],\n",
       "                        [ 2.6273e-01,  2.9016e-02,  9.1283e-02],\n",
       "                        [ 1.8607e-01,  1.7317e-01, -1.4859e-01]],\n",
       "              \n",
       "                       [[ 3.2339e-02,  3.9344e-02, -7.6753e-02],\n",
       "                        [-1.2953e-02,  1.2210e-01,  3.8187e-02],\n",
       "                        [-1.0272e-01, -8.2568e-02, -1.3936e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.4280e-01,  1.8871e-01,  1.7775e-01],\n",
       "                        [-1.4486e-01, -1.9612e-01,  1.2095e-01],\n",
       "                        [-1.1661e-01, -1.6383e-01,  1.2709e-01]],\n",
       "              \n",
       "                       [[ 3.4292e-02, -3.3006e-02, -1.2987e-01],\n",
       "                        [-2.3264e-02, -1.2288e-01, -1.9286e-01],\n",
       "                        [-2.9999e-01, -2.9824e-01, -2.3169e-01]],\n",
       "              \n",
       "                       [[-7.6839e-02,  8.4044e-02,  7.1974e-02],\n",
       "                        [ 8.5941e-02, -2.0281e-01,  1.0729e-01],\n",
       "                        [-1.1913e-01,  1.1005e-01, -2.9973e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.9741e-02,  2.1330e-01,  3.1865e-01],\n",
       "                        [ 2.3232e-01,  3.4308e-01,  3.4358e-01],\n",
       "                        [-1.5300e-01,  1.0074e-01,  2.4746e-01]],\n",
       "              \n",
       "                       [[ 1.5892e-04,  1.8080e-01,  9.8057e-02],\n",
       "                        [-1.0607e-01,  5.4794e-02, -2.8082e-02],\n",
       "                        [-1.5050e-01, -1.4501e-01, -3.3520e-02]],\n",
       "              \n",
       "                       [[-1.3769e-02,  5.0050e-02, -4.5862e-02],\n",
       "                        [-1.3355e-01,  1.6201e-01, -1.1863e-02],\n",
       "                        [ 2.9445e-02, -2.0883e-01,  8.4878e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0600e-01, -2.1596e-01, -1.8930e-01],\n",
       "                        [-1.0922e-01,  3.7088e-02, -3.3982e-02],\n",
       "                        [-2.1613e-01,  1.3204e-01,  3.4972e-02]],\n",
       "              \n",
       "                       [[ 2.8975e-02, -1.5815e-01,  5.1192e-02],\n",
       "                        [ 1.1981e-01, -3.4521e-02, -2.1686e-01],\n",
       "                        [-1.6651e-03, -6.7075e-02, -6.2847e-02]],\n",
       "              \n",
       "                       [[-2.0115e-01, -1.1968e-01,  7.2732e-02],\n",
       "                        [-5.1521e-02, -1.3042e-02, -1.6270e-01],\n",
       "                        [ 1.0718e-01,  1.0573e-01,  1.4428e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.6473e-02,  7.8276e-02, -7.2052e-02],\n",
       "                        [ 1.8734e-01,  2.6692e-01,  7.9629e-02],\n",
       "                        [ 5.6645e-02,  2.4471e-01,  3.3283e-02]],\n",
       "              \n",
       "                       [[ 1.5489e-01,  1.6982e-01, -6.3836e-02],\n",
       "                        [ 7.0046e-03, -4.0743e-02,  5.5431e-02],\n",
       "                        [-1.2523e-01,  1.2729e-01,  9.1833e-02]],\n",
       "              \n",
       "                       [[-2.3894e-02,  1.3909e-01, -1.6134e-01],\n",
       "                        [ 1.0223e-01, -7.5701e-02, -9.3745e-02],\n",
       "                        [-3.0813e-01,  3.6742e-02, -8.9108e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2607e-02, -1.7212e-01,  1.4134e-01],\n",
       "                        [ 1.6738e-01,  5.5385e-03,  1.2091e-01],\n",
       "                        [ 2.2855e-02,  3.4939e-02, -2.1199e-01]],\n",
       "              \n",
       "                       [[ 1.4718e-01,  6.7778e-02,  1.1975e-01],\n",
       "                        [-9.5814e-02, -7.4541e-02, -1.9256e-01],\n",
       "                        [-1.0364e-01, -1.8557e-01, -2.6350e-01]],\n",
       "              \n",
       "                       [[ 9.2020e-02, -7.9609e-02,  1.3512e-01],\n",
       "                        [-2.3183e-01, -2.2395e-01, -5.0917e-02],\n",
       "                        [ 8.0912e-02, -2.2127e-01, -2.0050e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1454e-01, -1.1652e-01, -1.0443e-01],\n",
       "                        [ 1.7859e-01,  7.9128e-02, -3.8159e-02],\n",
       "                        [ 9.7109e-02, -1.4051e-01, -1.7445e-02]],\n",
       "              \n",
       "                       [[-1.3246e-01, -1.6803e-01, -1.9911e-01],\n",
       "                        [-2.8362e-03, -3.2638e-01, -1.3995e-01],\n",
       "                        [-6.4280e-02, -1.9426e-01, -9.9126e-02]],\n",
       "              \n",
       "                       [[ 6.1208e-02,  1.6261e-01,  1.2071e-01],\n",
       "                        [-6.5221e-02,  1.2424e-01,  7.4109e-03],\n",
       "                        [ 7.3814e-02, -5.7145e-02,  1.4661e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.1403e-02,  1.3972e-01,  1.4359e-01],\n",
       "                        [-1.4135e-01,  8.2220e-02,  4.3290e-03],\n",
       "                        [-1.9483e-01, -1.8072e-01, -1.3318e-01]],\n",
       "              \n",
       "                       [[ 2.4476e-03, -1.7390e-01,  3.3322e-02],\n",
       "                        [ 9.4194e-02,  1.0308e-01, -5.2235e-02],\n",
       "                        [ 1.5477e-01, -1.7374e-02, -1.9766e-01]],\n",
       "              \n",
       "                       [[-1.4140e-01, -6.0422e-02, -1.2476e-01],\n",
       "                        [ 1.3226e-02,  1.6481e-01,  8.7298e-02],\n",
       "                        [-1.1596e-01, -1.2743e-01, -1.1340e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4913e-01, -5.7343e-02, -1.3732e-01],\n",
       "                        [ 3.5883e-02,  1.7190e-01,  4.3345e-02],\n",
       "                        [ 9.2184e-02,  2.4649e-01,  2.7429e-01]],\n",
       "              \n",
       "                       [[-1.0900e-01,  5.4716e-02, -1.8520e-01],\n",
       "                        [-2.5150e-01,  2.4825e-03, -1.0610e-01],\n",
       "                        [-2.0307e-01, -1.4458e-01,  6.7920e-02]],\n",
       "              \n",
       "                       [[-1.9207e-01, -7.4773e-02,  9.9912e-02],\n",
       "                        [ 1.3004e-01,  1.0523e-01, -1.6762e-01],\n",
       "                        [-1.1538e-01, -1.9159e-02, -2.3434e-02]]]])),\n",
       "             ('conv_block_1.0.bias',\n",
       "              tensor([ 0.0181, -0.0290,  0.3124, -0.2242, -0.0474, -0.1489,  0.0646,  0.1490,\n",
       "                      -0.1703,  0.1619])),\n",
       "             ('conv_block_1.2.weight',\n",
       "              tensor([[[[-1.1884e-02,  1.3398e-01,  2.8643e-01],\n",
       "                        [-1.1964e-01,  1.0148e-02,  7.9605e-02],\n",
       "                        [-3.6055e-01, -1.9149e-01,  1.7883e-01]],\n",
       "              \n",
       "                       [[-3.1185e-02, -2.9582e-02, -7.0183e-02],\n",
       "                        [ 4.5681e-02, -1.6934e-01, -6.8887e-02],\n",
       "                        [-4.7007e-02, -1.3202e-01, -7.0816e-02]],\n",
       "              \n",
       "                       [[ 2.4674e-02,  8.7870e-02,  1.3336e-01],\n",
       "                        [ 1.5474e-01,  4.7053e-02,  8.2096e-02],\n",
       "                        [ 6.4032e-02,  1.8198e-01,  1.3916e-01]],\n",
       "              \n",
       "                       [[-1.0310e-01, -5.6299e-02,  1.3565e-01],\n",
       "                        [-1.4072e-01, -1.5494e-01,  1.4530e-01],\n",
       "                        [-1.3944e-01, -8.9674e-02, -1.0967e-02]],\n",
       "              \n",
       "                       [[ 7.5412e-02, -7.1936e-03, -4.2710e-02],\n",
       "                        [-8.5056e-02,  7.6291e-02,  6.1087e-02],\n",
       "                        [-8.5815e-02,  6.0725e-02,  4.0861e-02]],\n",
       "              \n",
       "                       [[ 6.0513e-02,  7.8797e-02, -1.8156e-03],\n",
       "                        [-7.2313e-02, -1.9192e-01, -6.3690e-02],\n",
       "                        [-1.4059e-01, -2.0564e-01, -4.5395e-02]],\n",
       "              \n",
       "                       [[ 1.3561e-01, -1.7409e-03,  1.5301e-01],\n",
       "                        [-1.8563e-02,  6.4324e-03, -7.0523e-02],\n",
       "                        [ 1.3552e-01,  4.1187e-02,  6.8678e-02]],\n",
       "              \n",
       "                       [[ 7.7165e-02, -1.4517e-02, -9.0609e-02],\n",
       "                        [ 5.5466e-02,  7.3727e-02,  2.4437e-02],\n",
       "                        [ 7.4324e-02,  1.2062e-01, -4.2967e-02]],\n",
       "              \n",
       "                       [[ 9.7113e-03, -8.1089e-02,  7.1410e-02],\n",
       "                        [ 3.4582e-02, -7.2296e-02,  9.6802e-02],\n",
       "                        [-9.9423e-02,  1.5881e-02, -6.7551e-02]],\n",
       "              \n",
       "                       [[-1.7547e-01, -5.3687e-02,  1.0699e-01],\n",
       "                        [ 3.8268e-02,  1.4072e-01,  1.5431e-01],\n",
       "                        [-1.6932e-03, -2.1305e-02,  6.5249e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.4718e-02,  2.5487e-02,  2.5804e-02],\n",
       "                        [ 1.2485e-02,  1.1327e-01,  7.6600e-02],\n",
       "                        [-4.5814e-03, -8.9016e-02,  5.0182e-03]],\n",
       "              \n",
       "                       [[-1.2854e-01, -1.7620e-02, -7.3460e-02],\n",
       "                        [-4.5979e-02, -3.4069e-02,  6.3049e-02],\n",
       "                        [-1.1559e-01,  2.9731e-02, -1.4021e-01]],\n",
       "              \n",
       "                       [[-4.7391e-03,  4.3353e-02, -9.3744e-02],\n",
       "                        [-2.2025e-02, -8.6214e-02, -1.2324e-01],\n",
       "                        [-3.3172e-03, -8.1709e-02,  4.5857e-02]],\n",
       "              \n",
       "                       [[-7.3460e-02,  5.6289e-03, -9.5131e-02],\n",
       "                        [ 3.2930e-02,  6.7934e-03, -1.3431e-02],\n",
       "                        [-5.7881e-02,  3.8412e-02,  1.5468e-02]],\n",
       "              \n",
       "                       [[ 7.5497e-02,  4.5172e-02, -4.6622e-02],\n",
       "                        [ 6.0695e-02, -1.4071e-01,  3.7113e-02],\n",
       "                        [-1.3763e-01, -7.4883e-02,  1.4395e-02]],\n",
       "              \n",
       "                       [[-7.9298e-03, -1.2956e-01, -6.1197e-02],\n",
       "                        [ 3.0331e-03, -2.5413e-02,  5.4043e-02],\n",
       "                        [ 3.0023e-02, -1.3345e-01,  1.5529e-02]],\n",
       "              \n",
       "                       [[ 1.7236e-02, -6.2861e-02, -5.5558e-02],\n",
       "                        [-7.4888e-02, -8.1733e-02,  1.7630e-02],\n",
       "                        [ 5.7145e-02, -6.8104e-02,  1.0770e-01]],\n",
       "              \n",
       "                       [[-1.0389e-01, -1.2851e-01, -6.6829e-02],\n",
       "                        [ 1.0560e-03, -1.1919e-01, -6.3078e-02],\n",
       "                        [ 6.0801e-02, -5.8115e-02, -9.7491e-02]],\n",
       "              \n",
       "                       [[-7.9099e-02, -7.6026e-02,  9.6140e-02],\n",
       "                        [-4.8181e-02, -9.1933e-02, -6.8118e-02],\n",
       "                        [-4.8799e-02,  4.6891e-02, -1.1944e-02]],\n",
       "              \n",
       "                       [[ 3.6502e-02,  5.1021e-02,  6.7609e-02],\n",
       "                        [ 2.6454e-02,  1.6276e-02,  5.2320e-02],\n",
       "                        [-3.4802e-02,  8.6153e-02, -7.6501e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.6388e-02,  5.4263e-03, -5.0777e-02],\n",
       "                        [ 9.5629e-02,  4.6325e-02,  2.6718e-02],\n",
       "                        [-7.4235e-02,  1.7657e-01, -2.0975e-01]],\n",
       "              \n",
       "                       [[-9.1318e-02,  4.6764e-02,  1.3686e-01],\n",
       "                        [ 1.1991e-01,  3.1242e-02,  1.2880e-01],\n",
       "                        [ 1.9484e-02,  1.0249e-01,  1.2956e-01]],\n",
       "              \n",
       "                       [[-2.5576e-01, -3.5141e-01, -2.1874e-01],\n",
       "                        [-2.3652e-01, -1.9960e-01, -2.1086e-01],\n",
       "                        [-1.4692e-01, -1.6871e-01, -2.1875e-01]],\n",
       "              \n",
       "                       [[ 1.5211e-01,  9.6343e-02, -2.3533e-01],\n",
       "                        [ 1.3253e-01,  1.8031e-01,  4.8759e-02],\n",
       "                        [ 2.4039e-01,  3.0518e-01,  2.0802e-02]],\n",
       "              \n",
       "                       [[-3.2403e-02, -2.8021e-02,  4.9395e-02],\n",
       "                        [-2.3535e-02, -3.2902e-02, -8.2622e-02],\n",
       "                        [ 1.2593e-01,  1.3164e-02,  1.6888e-01]],\n",
       "              \n",
       "                       [[-9.5660e-03,  4.7733e-04, -3.2390e-02],\n",
       "                        [ 1.2101e-01,  8.4111e-02,  1.4069e-01],\n",
       "                        [ 6.0536e-02,  3.3093e-02,  1.5346e-01]],\n",
       "              \n",
       "                       [[-1.0878e-01,  4.8422e-02, -2.2677e-02],\n",
       "                        [-1.1635e-01,  2.9091e-02,  2.8409e-03],\n",
       "                        [ 3.6119e-02, -1.3671e-02,  1.7531e-02]],\n",
       "              \n",
       "                       [[-1.3585e-01,  5.1686e-02,  7.5349e-02],\n",
       "                        [-1.2680e-02, -4.5571e-02,  9.2730e-02],\n",
       "                        [-1.3574e-01,  2.1356e-02,  1.1482e-02]],\n",
       "              \n",
       "                       [[ 6.7070e-02, -7.9771e-02,  7.7758e-02],\n",
       "                        [ 8.8252e-03, -3.8943e-02, -1.7724e-02],\n",
       "                        [ 2.3848e-02,  9.7098e-02, -2.4348e-02]],\n",
       "              \n",
       "                       [[ 1.7550e-01,  1.1089e-01,  1.1884e-02],\n",
       "                        [-6.0440e-03, -6.1213e-02, -3.6449e-02],\n",
       "                        [ 1.5465e-02, -1.1651e-01, -1.1055e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.2492e-02,  7.4497e-02, -1.5243e-01],\n",
       "                        [-1.2626e-02,  5.5374e-02,  4.7144e-02],\n",
       "                        [ 3.4883e-02, -3.9612e-02, -2.3195e-02]],\n",
       "              \n",
       "                       [[ 1.4342e-01,  1.4209e-02,  8.2383e-02],\n",
       "                        [ 7.5903e-02,  5.2874e-02, -7.4115e-02],\n",
       "                        [ 1.4571e-01,  1.4449e-01,  3.6268e-02]],\n",
       "              \n",
       "                       [[-1.4604e-01, -2.3271e-01, -2.0668e-02],\n",
       "                        [-6.4117e-02, -1.0252e-01, -2.3130e-02],\n",
       "                        [-1.0861e-01, -1.2680e-01, -6.0508e-02]],\n",
       "              \n",
       "                       [[-5.2946e-02,  1.4451e-02, -1.3090e-01],\n",
       "                        [ 8.1832e-02, -6.2228e-02, -1.1505e-01],\n",
       "                        [ 1.6388e-01,  3.2186e-02, -2.5219e-01]],\n",
       "              \n",
       "                       [[ 5.0235e-02,  3.5182e-02, -5.8221e-02],\n",
       "                        [ 3.8473e-02,  3.4394e-02, -6.6636e-02],\n",
       "                        [-2.3722e-02,  7.6326e-04, -4.7327e-02]],\n",
       "              \n",
       "                       [[ 1.5253e-01, -1.2587e-01, -1.1214e-01],\n",
       "                        [ 1.7154e-01, -1.0007e-01, -1.3112e-01],\n",
       "                        [ 1.1334e-01,  3.8188e-02,  1.5935e-02]],\n",
       "              \n",
       "                       [[ 9.5694e-02,  1.6421e-02, -5.8560e-02],\n",
       "                        [ 3.2967e-02, -3.9091e-02,  4.5116e-02],\n",
       "                        [ 9.7534e-03,  7.0479e-02, -3.1639e-02]],\n",
       "              \n",
       "                       [[-1.0004e-01, -2.6147e-02, -9.2819e-03],\n",
       "                        [ 5.0697e-02,  6.0427e-02,  1.2860e-01],\n",
       "                        [-1.2687e-04, -1.1459e-02,  1.4758e-01]],\n",
       "              \n",
       "                       [[-6.5234e-02, -6.1312e-02, -6.9642e-03],\n",
       "                        [-7.9358e-02,  1.0451e-03,  7.5844e-02],\n",
       "                        [-7.4579e-02, -7.7794e-02, -6.2901e-02]],\n",
       "              \n",
       "                       [[ 9.7568e-02, -1.1101e-01,  8.7717e-02],\n",
       "                        [-8.9778e-02, -2.5295e-02, -8.9817e-02],\n",
       "                        [-3.7763e-02, -2.1038e-01, -1.4508e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5151e-02, -9.8809e-02,  5.8205e-02],\n",
       "                        [ 8.8684e-02,  7.0460e-02, -4.7203e-02],\n",
       "                        [-8.1453e-02,  2.4431e-02, -8.1262e-03]],\n",
       "              \n",
       "                       [[ 5.1402e-02,  5.5275e-02,  2.1625e-02],\n",
       "                        [-7.4393e-02, -1.2169e-02, -6.7045e-02],\n",
       "                        [-3.3490e-02,  5.7075e-02, -1.2379e-02]],\n",
       "              \n",
       "                       [[-2.9943e-02, -1.1454e-01, -3.4294e-03],\n",
       "                        [ 3.3439e-02,  6.2681e-02,  4.1255e-02],\n",
       "                        [-4.3815e-02, -9.3187e-02, -1.1449e-01]],\n",
       "              \n",
       "                       [[-4.2792e-02, -8.6152e-02,  2.4756e-02],\n",
       "                        [-5.1026e-02, -5.2926e-02, -6.2888e-02],\n",
       "                        [-5.4786e-03,  2.6255e-02,  4.2964e-02]],\n",
       "              \n",
       "                       [[ 1.5417e-02, -3.0606e-03,  6.8089e-02],\n",
       "                        [-5.5209e-02,  1.8352e-02, -7.3642e-02],\n",
       "                        [-2.0628e-02,  1.2111e-02, -3.5017e-02]],\n",
       "              \n",
       "                       [[ 2.1409e-02, -1.3831e-01, -2.5867e-03],\n",
       "                        [ 4.0631e-02, -1.4304e-02, -1.3564e-01],\n",
       "                        [-1.7707e-02,  2.5968e-02,  5.1811e-02]],\n",
       "              \n",
       "                       [[-9.9249e-02, -4.7946e-02, -3.9136e-02],\n",
       "                        [-3.9848e-02,  2.8786e-02,  5.1596e-02],\n",
       "                        [-9.8632e-02, -9.8072e-02, -4.2209e-02]],\n",
       "              \n",
       "                       [[ 6.7476e-04, -4.3936e-02, -1.0330e-01],\n",
       "                        [-1.1950e-03, -1.5076e-02, -1.7513e-03],\n",
       "                        [-7.0973e-02, -1.3316e-01, -1.8266e-02]],\n",
       "              \n",
       "                       [[-6.2814e-02,  4.6887e-02,  5.7227e-02],\n",
       "                        [ 9.3037e-02,  6.0559e-02,  9.4825e-02],\n",
       "                        [ 4.2748e-02, -8.0548e-02, -2.5119e-02]],\n",
       "              \n",
       "                       [[ 4.9446e-02, -9.1207e-03, -6.6063e-02],\n",
       "                        [ 2.3043e-02, -8.4717e-02, -4.6340e-02],\n",
       "                        [ 7.0322e-02, -2.2237e-02, -4.7144e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.8837e-02, -1.2396e-01, -1.6875e-02],\n",
       "                        [-1.5512e-01, -5.9882e-02,  7.3555e-02],\n",
       "                        [-1.2281e-01, -1.6462e-01, -4.1860e-02]],\n",
       "              \n",
       "                       [[ 3.1485e-02,  5.3220e-03,  6.7411e-02],\n",
       "                        [-9.0084e-02, -9.1869e-02, -7.0587e-02],\n",
       "                        [ 5.6809e-02,  7.5720e-02,  5.3951e-02]],\n",
       "              \n",
       "                       [[-8.3456e-02, -2.6490e-02, -2.2056e-02],\n",
       "                        [-3.9438e-02,  4.2119e-02,  5.4322e-02],\n",
       "                        [ 2.7341e-02,  1.9047e-02,  6.7253e-02]],\n",
       "              \n",
       "                       [[-9.9569e-02, -2.7911e-02,  6.4669e-02],\n",
       "                        [-8.3099e-02, -4.4815e-02, -6.2420e-02],\n",
       "                        [-4.4420e-02, -1.0637e-01,  5.4239e-02]],\n",
       "              \n",
       "                       [[ 4.5925e-02, -2.2693e-03,  3.5389e-02],\n",
       "                        [ 8.0673e-02, -2.2103e-02, -1.8304e-02],\n",
       "                        [-7.4508e-02, -5.4847e-02, -8.5645e-03]],\n",
       "              \n",
       "                       [[-9.1640e-02, -1.9641e-02, -1.1602e-01],\n",
       "                        [-8.4577e-03, -9.0011e-02,  2.3054e-02],\n",
       "                        [ 4.6850e-02, -6.7521e-02, -4.8208e-02]],\n",
       "              \n",
       "                       [[ 1.3682e-02, -3.3445e-02,  1.5845e-02],\n",
       "                        [-6.6780e-02, -3.8130e-02, -9.1395e-02],\n",
       "                        [-1.1782e-02,  3.3678e-02,  7.4589e-02]],\n",
       "              \n",
       "                       [[ 3.2648e-02, -9.7287e-02,  4.8402e-02],\n",
       "                        [ 3.5822e-02, -5.2416e-02, -4.6325e-03],\n",
       "                        [-4.4411e-03,  3.6525e-02,  7.4882e-02]],\n",
       "              \n",
       "                       [[-9.5955e-02,  4.6467e-03,  4.2748e-02],\n",
       "                        [-6.2675e-02,  7.4259e-02,  7.3589e-03],\n",
       "                        [-9.5689e-02, -2.6376e-03,  9.6114e-02]],\n",
       "              \n",
       "                       [[-5.3339e-02,  5.1651e-02, -8.7802e-02],\n",
       "                        [-3.6253e-02, -5.4238e-02,  8.2155e-02],\n",
       "                        [ 7.9514e-02,  6.5564e-03, -6.3503e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.4032e-02,  4.8472e-02, -4.6384e-02],\n",
       "                        [-1.7540e-02, -3.6505e-02,  7.0050e-02],\n",
       "                        [-1.0533e-01, -8.2244e-02,  1.5075e-02]],\n",
       "              \n",
       "                       [[-8.2922e-02, -1.3208e-01, -1.0627e-01],\n",
       "                        [-1.0899e-01, -9.5264e-02,  7.6814e-03],\n",
       "                        [-1.3861e-01, -8.3982e-02, -9.4986e-02]],\n",
       "              \n",
       "                       [[-3.5851e-02, -8.4110e-03, -4.5546e-02],\n",
       "                        [-5.2254e-02, -1.2203e-01, -5.6753e-02],\n",
       "                        [ 4.8993e-02, -1.7067e-03, -1.2510e-01]],\n",
       "              \n",
       "                       [[-1.8424e-02, -2.0054e-02, -8.3118e-04],\n",
       "                        [ 5.0392e-02,  1.6422e-03,  2.0059e-02],\n",
       "                        [-4.4013e-02,  7.7230e-02, -9.6101e-02]],\n",
       "              \n",
       "                       [[-1.8410e-02, -7.5836e-03,  2.8464e-02],\n",
       "                        [ 9.3396e-02, -9.7383e-02,  1.0269e-01],\n",
       "                        [ 2.7890e-02,  1.0467e-01, -1.0058e-01]],\n",
       "              \n",
       "                       [[ 1.7018e-02, -6.8092e-02, -9.8619e-02],\n",
       "                        [-3.5872e-02, -1.0215e-01, -1.4883e-01],\n",
       "                        [ 4.4771e-02, -1.0702e-02, -7.6168e-02]],\n",
       "              \n",
       "                       [[ 4.1641e-02,  3.2984e-02, -9.6953e-02],\n",
       "                        [ 1.4699e-02,  2.8501e-02, -1.1763e-01],\n",
       "                        [-7.6211e-03, -3.8161e-02,  5.8417e-02]],\n",
       "              \n",
       "                       [[-3.1859e-03, -4.7428e-02, -5.6595e-02],\n",
       "                        [-4.0745e-03, -9.8162e-02, -1.0910e-01],\n",
       "                        [-8.6282e-02, -4.1061e-02,  2.8501e-02]],\n",
       "              \n",
       "                       [[ 6.1288e-02, -7.9685e-02,  6.0132e-02],\n",
       "                        [-5.9917e-02,  2.3985e-02, -4.4117e-02],\n",
       "                        [-6.3151e-02,  1.4906e-03,  1.1051e-02]],\n",
       "              \n",
       "                       [[-3.9499e-02, -4.0478e-02, -6.0086e-02],\n",
       "                        [-1.3311e-01, -1.3589e-01,  7.5563e-02],\n",
       "                        [-6.6613e-02, -1.2765e-01, -7.6180e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.5382e-02,  3.7209e-02,  7.3170e-02],\n",
       "                        [ 1.6829e-01,  7.6750e-02,  1.8470e-01],\n",
       "                        [ 9.4728e-02,  2.0720e-01, -2.2104e-02]],\n",
       "              \n",
       "                       [[ 9.8719e-02,  1.1790e-01,  1.4985e-01],\n",
       "                        [-1.1998e-01, -6.0614e-02, -6.3582e-03],\n",
       "                        [-1.6788e-01, -9.7278e-02, -9.3284e-02]],\n",
       "              \n",
       "                       [[-2.1426e-01, -2.4138e-01, -1.2681e-01],\n",
       "                        [ 2.6130e-01,  2.1310e-01,  3.1204e-01],\n",
       "                        [ 2.7466e-01,  2.1540e-01,  2.7503e-01]],\n",
       "              \n",
       "                       [[ 3.7718e-01,  2.8958e-01,  1.8722e-01],\n",
       "                        [ 1.5806e-01,  2.5434e-01,  1.9144e-01],\n",
       "                        [-1.9120e-01,  1.1722e-01, -1.8985e-02]],\n",
       "              \n",
       "                       [[-1.1788e-02, -6.6371e-02,  4.9690e-02],\n",
       "                        [ 6.3312e-03,  6.6446e-02, -6.6666e-02],\n",
       "                        [-3.2840e-02,  3.7266e-02,  2.9556e-02]],\n",
       "              \n",
       "                       [[ 1.5867e-01,  1.1244e-01,  1.7680e-01],\n",
       "                        [-1.1354e-02,  8.8404e-02,  1.1620e-01],\n",
       "                        [-2.8211e-01, -1.4427e-01, -5.7301e-02]],\n",
       "              \n",
       "                       [[ 9.1160e-02,  5.1906e-02,  2.6175e-02],\n",
       "                        [ 5.6466e-02, -5.2198e-02, -3.0049e-03],\n",
       "                        [-4.1590e-02, -2.0663e-01, -1.9237e-01]],\n",
       "              \n",
       "                       [[-1.3813e-01,  8.0599e-02,  3.3179e-02],\n",
       "                        [-1.4982e-01, -3.2409e-02,  1.4950e-01],\n",
       "                        [-1.0944e-01,  2.3243e-02,  7.3691e-02]],\n",
       "              \n",
       "                       [[ 8.3762e-02,  3.7117e-02,  4.8198e-02],\n",
       "                        [-9.0388e-02,  5.1856e-02, -1.0121e-01],\n",
       "                        [-2.5027e-02, -8.4335e-02, -6.2098e-02]],\n",
       "              \n",
       "                       [[-6.7866e-02, -9.9767e-02, -1.5504e-02],\n",
       "                        [-2.5981e-01, -2.0979e-01, -1.7879e-01],\n",
       "                        [-2.2220e-01, -6.3061e-02, -4.5923e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9901e-02,  9.2668e-02,  1.0634e-01],\n",
       "                        [-5.5367e-02,  1.0365e-01, -1.1132e-02],\n",
       "                        [-1.1023e-01, -9.5479e-02, -1.1093e-01]],\n",
       "              \n",
       "                       [[-1.2315e-01, -8.3765e-02,  5.0882e-02],\n",
       "                        [-4.8509e-02,  1.7038e-03,  4.2353e-02],\n",
       "                        [ 6.6710e-02, -4.9809e-02, -3.8755e-02]],\n",
       "              \n",
       "                       [[-4.2120e-02, -8.7281e-03, -2.1973e-02],\n",
       "                        [-8.8056e-02,  1.4131e-02,  7.5877e-02],\n",
       "                        [-1.4700e-02, -9.6585e-02, -1.0522e-01]],\n",
       "              \n",
       "                       [[-1.7108e-02, -3.2348e-02, -9.9779e-02],\n",
       "                        [-1.4241e-01, -7.8202e-02, -2.7583e-02],\n",
       "                        [-7.2091e-02, -1.1975e-02, -1.0719e-02]],\n",
       "              \n",
       "                       [[ 2.7323e-02, -9.4285e-02, -1.0538e-01],\n",
       "                        [ 8.7876e-02,  6.7583e-02,  4.4991e-02],\n",
       "                        [-1.2959e-02,  5.3642e-02, -9.4350e-02]],\n",
       "              \n",
       "                       [[ 4.9289e-02, -9.6033e-03,  4.5966e-03],\n",
       "                        [ 2.8302e-02,  5.3209e-02, -5.2730e-02],\n",
       "                        [-1.0697e-01, -2.1854e-02, -1.1515e-01]],\n",
       "              \n",
       "                       [[-9.8621e-02,  2.8919e-02, -8.7393e-02],\n",
       "                        [-2.3521e-02, -1.4744e-02,  5.1231e-02],\n",
       "                        [-5.1300e-02, -9.0694e-02,  5.4232e-02]],\n",
       "              \n",
       "                       [[-2.9546e-02, -2.4648e-02, -3.3917e-02],\n",
       "                        [-7.1257e-02, -7.1055e-02,  6.6418e-02],\n",
       "                        [ 2.4123e-02, -6.4837e-02,  8.8434e-02]],\n",
       "              \n",
       "                       [[-2.9947e-02, -1.0319e-01, -8.2091e-02],\n",
       "                        [ 6.4917e-03, -3.6106e-02, -1.0483e-01],\n",
       "                        [-4.2482e-02, -4.4964e-02,  9.0750e-03]],\n",
       "              \n",
       "                       [[-7.3099e-03, -6.4337e-02,  7.9488e-02],\n",
       "                        [-2.8439e-02, -7.9982e-02,  4.8108e-02],\n",
       "                        [ 8.2657e-02, -7.9436e-02, -9.9754e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.7169e-01,  1.5332e-02, -4.9435e-02],\n",
       "                        [-7.5537e-03,  1.1909e-03,  1.8054e-02],\n",
       "                        [ 8.9686e-02,  2.0285e-01, -6.3162e-02]],\n",
       "              \n",
       "                       [[-1.4671e-01,  7.4353e-02,  1.0629e-01],\n",
       "                        [-7.2946e-02,  7.4932e-02, -7.1124e-03],\n",
       "                        [ 4.9967e-02,  4.8452e-02,  1.1393e-01]],\n",
       "              \n",
       "                       [[-2.2461e-01, -1.7486e-01, -3.6954e-01],\n",
       "                        [-1.9819e-01, -3.0853e-01, -2.6914e-01],\n",
       "                        [ 2.5787e-02, -1.8139e-01, -1.4135e-01]],\n",
       "              \n",
       "                       [[ 7.0928e-02,  1.0036e-01, -1.2143e-01],\n",
       "                        [ 9.9108e-02,  6.6655e-02, -1.7706e-01],\n",
       "                        [-3.2378e-02,  2.2013e-01, -1.2597e-03]],\n",
       "              \n",
       "                       [[-3.2653e-02,  1.4051e-01,  1.1363e-01],\n",
       "                        [ 9.6561e-02,  1.1996e-02, -7.3342e-02],\n",
       "                        [-8.0016e-02, -1.2172e-02, -3.7445e-02]],\n",
       "              \n",
       "                       [[-1.8477e-01,  5.8730e-02,  1.1174e-01],\n",
       "                        [-7.6137e-02,  6.9896e-02,  1.4967e-01],\n",
       "                        [-1.0403e-01, -1.0487e-01,  1.3998e-01]],\n",
       "              \n",
       "                       [[-1.4445e-02, -8.3882e-02,  1.2290e-01],\n",
       "                        [-1.8266e-01, -1.4626e-01, -4.2141e-02],\n",
       "                        [-2.0059e-01, -8.7130e-02, -1.7302e-02]],\n",
       "              \n",
       "                       [[-8.6628e-02, -1.0125e-01, -8.6998e-02],\n",
       "                        [-6.3830e-02, -7.2780e-02, -1.0184e-01],\n",
       "                        [-8.1475e-02, -7.1249e-02, -9.7866e-02]],\n",
       "              \n",
       "                       [[-4.5135e-02,  3.0768e-02,  9.3188e-03],\n",
       "                        [ 1.3764e-02,  9.6332e-02, -3.1567e-02],\n",
       "                        [ 7.3280e-02,  5.6740e-02, -6.9566e-02]],\n",
       "              \n",
       "                       [[ 2.0758e-01,  1.3248e-01,  5.5631e-02],\n",
       "                        [ 7.5434e-02,  4.3398e-02, -1.4323e-01],\n",
       "                        [-8.4730e-02, -1.2945e-01, -1.2823e-01]]]])),\n",
       "             ('conv_block_1.2.bias',\n",
       "              tensor([ 0.0717, -0.0655, -0.0657, -0.0831, -0.0736, -0.0930,  0.0509, -0.1733,\n",
       "                      -0.0553,  0.0921])),\n",
       "             ('conv_block_2.0.weight',\n",
       "              tensor([[[[ 7.5984e-02, -6.2243e-02,  4.6101e-02],\n",
       "                        [-1.0110e-01,  3.4847e-02, -7.8018e-02],\n",
       "                        [-1.1561e-01, -1.2238e-01, -7.3458e-02]],\n",
       "              \n",
       "                       [[-1.6051e-03, -3.8813e-02,  4.6733e-02],\n",
       "                        [ 2.0938e-02, -8.1071e-02, -1.6524e-02],\n",
       "                        [ 1.2340e-03, -5.2997e-02, -1.1942e-01]],\n",
       "              \n",
       "                       [[-8.5166e-02, -2.8697e-02, -7.2594e-02],\n",
       "                        [ 5.4960e-02, -1.1292e-01, -1.2526e-01],\n",
       "                        [-6.0588e-02, -5.4916e-03, -1.2352e-01]],\n",
       "              \n",
       "                       [[-9.2740e-02, -1.0150e-01,  3.6548e-02],\n",
       "                        [-9.5338e-02,  7.7851e-02,  5.4654e-02],\n",
       "                        [-2.7364e-02, -3.2655e-02,  2.8023e-03]],\n",
       "              \n",
       "                       [[ 1.1987e-02,  1.3493e-02,  2.5575e-02],\n",
       "                        [-9.5577e-02, -8.1874e-02,  8.3762e-02],\n",
       "                        [ 7.2159e-02,  2.2285e-02, -1.3758e-02]],\n",
       "              \n",
       "                       [[-8.2840e-02,  7.6385e-02,  6.2859e-02],\n",
       "                        [ 9.6379e-02, -5.6958e-02,  1.4688e-02],\n",
       "                        [ 4.6110e-02,  4.5815e-02, -8.6445e-02]],\n",
       "              \n",
       "                       [[ 5.3574e-02,  2.6530e-02,  6.1090e-02],\n",
       "                        [-1.0452e-01, -4.4033e-02,  3.4306e-02],\n",
       "                        [-1.3580e-02,  5.9886e-02,  4.3276e-02]],\n",
       "              \n",
       "                       [[-1.5277e-01, -7.0199e-02, -4.4632e-02],\n",
       "                        [ 6.6143e-02,  2.7733e-02, -1.3034e-01],\n",
       "                        [-4.1851e-02, -1.1031e-01, -4.9650e-02]],\n",
       "              \n",
       "                       [[-8.6878e-02,  3.5136e-02,  6.1830e-02],\n",
       "                        [-8.6094e-03,  3.6110e-02, -8.7067e-02],\n",
       "                        [ 9.5155e-02,  1.6592e-02,  2.9968e-02]],\n",
       "              \n",
       "                       [[-6.3514e-02, -4.5318e-02,  7.2724e-02],\n",
       "                        [-1.2159e-01,  8.7062e-02, -3.3953e-02],\n",
       "                        [ 7.0287e-02, -9.0107e-02,  4.9266e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1121e-01,  7.5802e-02,  4.0367e-02],\n",
       "                        [ 7.1993e-02, -3.6071e-02,  2.9932e-02],\n",
       "                        [-7.5650e-03, -4.8178e-05,  1.0698e-01]],\n",
       "              \n",
       "                       [[-1.0163e-01, -1.1019e-01, -6.0996e-02],\n",
       "                        [ 5.8180e-02, -9.2627e-02,  2.6032e-02],\n",
       "                        [ 7.7615e-02, -7.2981e-02, -7.0030e-02]],\n",
       "              \n",
       "                       [[-3.5074e-02, -7.7241e-02, -1.8511e-02],\n",
       "                        [-4.1067e-03,  6.9175e-02,  6.5298e-02],\n",
       "                        [-2.9282e-01,  9.1964e-02,  7.0168e-02]],\n",
       "              \n",
       "                       [[ 5.7908e-02,  7.0084e-02,  1.2081e-03],\n",
       "                        [-5.6808e-02,  4.2758e-02,  9.9512e-02],\n",
       "                        [-3.4108e-01, -9.2653e-02,  1.9405e-01]],\n",
       "              \n",
       "                       [[ 7.1434e-03,  3.1483e-02, -3.6512e-02],\n",
       "                        [-5.7193e-02,  2.1376e-02, -6.7160e-02],\n",
       "                        [ 1.5808e-02,  7.1144e-02,  9.1789e-02]],\n",
       "              \n",
       "                       [[-9.4084e-02,  1.0157e-01, -1.0084e-01],\n",
       "                        [-2.9982e-03,  9.9783e-02, -1.3039e-02],\n",
       "                        [ 1.2337e-03,  2.2981e-02, -2.1164e-02]],\n",
       "              \n",
       "                       [[-3.8734e-02, -4.6923e-02, -6.5757e-02],\n",
       "                        [-4.5975e-02,  2.4089e-02,  5.4586e-02],\n",
       "                        [-1.1491e-01, -7.3852e-02,  9.9327e-02]],\n",
       "              \n",
       "                       [[-3.5307e-02, -1.8745e-01, -1.7519e-01],\n",
       "                        [ 1.0827e-02, -1.2512e-02,  6.8978e-02],\n",
       "                        [-1.7041e-02,  1.5665e-01,  9.2952e-02]],\n",
       "              \n",
       "                       [[ 6.3156e-02, -5.7134e-02, -9.0617e-03],\n",
       "                        [-7.3240e-02,  7.7557e-02, -4.3392e-03],\n",
       "                        [ 6.0476e-02, -1.1048e-01, -3.8805e-02]],\n",
       "              \n",
       "                       [[-2.4419e-02, -1.0531e-01, -2.5770e-02],\n",
       "                        [-1.4485e-01,  1.3039e-01,  1.0726e-01],\n",
       "                        [-2.0008e-01,  1.8370e-01,  1.2273e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2171e-01,  5.8489e-03,  3.9634e-03],\n",
       "                        [-1.2321e-01,  5.8268e-02,  1.1141e-01],\n",
       "                        [-1.0736e-01, -1.7567e-02,  3.8458e-02]],\n",
       "              \n",
       "                       [[-9.6551e-02, -1.9130e-01, -1.3942e-01],\n",
       "                        [ 7.4478e-02, -1.0995e-01, -1.7856e-01],\n",
       "                        [-7.3523e-02, -1.2152e-01, -2.0347e-01]],\n",
       "              \n",
       "                       [[-1.0800e-01, -1.9019e-01, -2.0925e-01],\n",
       "                        [-7.6058e-02, -1.1050e-01, -1.2492e-01],\n",
       "                        [ 1.6028e-02, -2.7338e-02, -1.9622e-01]],\n",
       "              \n",
       "                       [[ 1.3303e-02, -7.0918e-02, -1.8931e-01],\n",
       "                        [ 6.8144e-03, -1.7923e-02, -1.2832e-01],\n",
       "                        [ 4.7186e-02,  1.9212e-03, -1.0101e-01]],\n",
       "              \n",
       "                       [[-5.5284e-02, -8.0663e-02,  4.0521e-02],\n",
       "                        [ 8.4746e-02,  2.8734e-02, -3.5616e-02],\n",
       "                        [ 5.1496e-02,  1.6383e-02, -3.0650e-02]],\n",
       "              \n",
       "                       [[-3.9515e-02, -7.1947e-02,  1.1037e-01],\n",
       "                        [-7.4833e-03,  6.0009e-02, -6.4591e-03],\n",
       "                        [-6.3547e-02, -1.9554e-02,  4.9450e-02]],\n",
       "              \n",
       "                       [[ 7.6059e-02,  2.9391e-02, -7.7999e-02],\n",
       "                        [ 4.9747e-02, -1.0499e-01, -4.8438e-02],\n",
       "                        [ 1.0335e-01,  7.6796e-02,  5.4950e-02]],\n",
       "              \n",
       "                       [[-1.6517e-01, -1.3421e-02, -1.6394e-02],\n",
       "                        [ 1.6331e-01,  1.9246e-01,  6.7746e-02],\n",
       "                        [-5.2594e-02,  9.0366e-02,  5.7317e-03]],\n",
       "              \n",
       "                       [[ 5.9732e-02, -6.6440e-02, -5.6829e-02],\n",
       "                        [-1.1351e-01, -4.2666e-02, -4.8970e-02],\n",
       "                        [ 8.9493e-02, -6.4977e-03, -5.4811e-03]],\n",
       "              \n",
       "                       [[-1.0005e-01, -1.2581e-01, -2.4159e-02],\n",
       "                        [ 1.3768e-02,  1.0309e-01, -1.0070e-03],\n",
       "                        [-6.9181e-02,  1.3341e-01, -1.9191e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.0968e-02, -6.6873e-02, -6.0236e-02],\n",
       "                        [-2.2513e-02,  1.0329e-01, -4.0243e-02],\n",
       "                        [-7.0380e-03,  8.5791e-02, -5.3016e-02]],\n",
       "              \n",
       "                       [[ 9.2967e-02, -1.9710e-02,  1.2890e-02],\n",
       "                        [-3.7996e-02, -1.1485e-01,  5.2013e-02],\n",
       "                        [ 3.5521e-02,  8.9078e-03,  1.9993e-02]],\n",
       "              \n",
       "                       [[-5.1200e-02, -9.1912e-02,  5.3167e-03],\n",
       "                        [ 6.3853e-02, -8.9966e-02,  5.8557e-02],\n",
       "                        [-1.2335e-02,  5.8903e-02, -7.6757e-02]],\n",
       "              \n",
       "                       [[ 3.0773e-02, -1.3617e-01, -1.3405e-01],\n",
       "                        [ 4.6360e-02,  2.9606e-02, -4.8165e-02],\n",
       "                        [-3.7078e-02, -4.4767e-02, -3.3799e-02]],\n",
       "              \n",
       "                       [[ 2.7140e-02, -3.7020e-02, -5.2010e-02],\n",
       "                        [ 3.7230e-05, -4.8827e-02, -7.7029e-02],\n",
       "                        [-5.6043e-02,  4.4795e-02,  7.0776e-02]],\n",
       "              \n",
       "                       [[ 6.6707e-02, -9.2320e-02,  4.7358e-03],\n",
       "                        [ 3.1244e-02,  5.6919e-02,  4.7806e-02],\n",
       "                        [-7.2880e-02,  5.7939e-02,  1.1024e-01]],\n",
       "              \n",
       "                       [[ 6.4141e-02, -1.3770e-02, -4.7637e-02],\n",
       "                        [-8.2451e-02,  4.3321e-02, -8.9992e-02],\n",
       "                        [ 6.0152e-03, -1.4672e-02,  8.7951e-02]],\n",
       "              \n",
       "                       [[ 5.0448e-02, -7.9533e-02,  6.5596e-02],\n",
       "                        [-1.3490e-01, -1.2971e-02, -1.0543e-01],\n",
       "                        [-6.7249e-03,  3.6433e-02,  7.6821e-03]],\n",
       "              \n",
       "                       [[-6.3921e-02,  6.2357e-03, -5.6084e-02],\n",
       "                        [-5.0934e-02, -8.5840e-02, -1.7396e-02],\n",
       "                        [-1.9785e-02, -2.1003e-03, -9.0720e-02]],\n",
       "              \n",
       "                       [[ 2.7718e-02, -7.5103e-02,  2.1808e-02],\n",
       "                        [-1.1364e-01, -1.2324e-02,  3.8122e-02],\n",
       "                        [ 2.8090e-02,  4.8099e-03, -7.0013e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.6204e-02, -9.5360e-02, -1.0014e-01],\n",
       "                        [ 6.6707e-02, -5.6968e-02, -1.8781e-02],\n",
       "                        [ 2.4570e-01, -6.7800e-02, -1.2315e-01]],\n",
       "              \n",
       "                       [[ 2.8904e-02,  8.7734e-02,  7.6010e-02],\n",
       "                        [-1.0525e-01,  2.8286e-02, -3.0048e-02],\n",
       "                        [ 6.4501e-02,  5.5727e-02, -5.7566e-02]],\n",
       "              \n",
       "                       [[ 1.2227e-02,  1.1679e-02,  3.0699e-02],\n",
       "                        [-1.5598e-01,  4.5415e-02, -6.5231e-02],\n",
       "                        [-2.6099e-01,  8.8014e-03,  1.3842e-01]],\n",
       "              \n",
       "                       [[ 1.5820e-01, -6.2565e-02, -8.6157e-02],\n",
       "                        [ 1.0347e-01, -4.1577e-02, -1.0677e-01],\n",
       "                        [-9.7523e-02,  1.0753e-01,  2.7229e-02]],\n",
       "              \n",
       "                       [[ 9.6453e-02, -6.7326e-02, -1.0832e-01],\n",
       "                        [ 8.2222e-02,  4.6515e-02, -9.5607e-02],\n",
       "                        [-3.0448e-02,  6.5176e-02, -4.2943e-02]],\n",
       "              \n",
       "                       [[ 1.9952e-02,  8.0634e-03, -1.1207e-01],\n",
       "                        [ 8.8723e-02, -6.6630e-02, -5.0360e-02],\n",
       "                        [ 8.7747e-02,  1.3098e-02,  6.8429e-02]],\n",
       "              \n",
       "                       [[ 4.2268e-02,  8.5934e-02,  9.1251e-02],\n",
       "                        [ 8.6013e-03, -5.1832e-02,  7.7640e-02],\n",
       "                        [-8.5840e-02, -7.0940e-02, -5.4085e-02]],\n",
       "              \n",
       "                       [[ 3.2555e-02, -1.2895e-01,  4.0759e-02],\n",
       "                        [-9.4573e-02, -1.2135e-01, -9.3689e-02],\n",
       "                        [ 8.4725e-02, -5.4935e-02,  4.6472e-02]],\n",
       "              \n",
       "                       [[ 3.1732e-02, -6.0566e-02, -5.2186e-02],\n",
       "                        [ 3.6372e-03, -3.3515e-02, -5.6241e-02],\n",
       "                        [ 1.1111e-01,  5.4039e-02,  4.1614e-02]],\n",
       "              \n",
       "                       [[ 1.2113e-01,  6.5440e-02,  1.2399e-02],\n",
       "                        [-9.7209e-03, -5.5273e-02,  7.2759e-02],\n",
       "                        [-1.8729e-01, -7.6743e-02,  9.7374e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0660e-01, -1.5639e-01, -1.7409e-01],\n",
       "                        [-1.1633e-01, -4.7411e-02, -3.8779e-02],\n",
       "                        [-2.1128e-01, -3.7218e-02,  5.7109e-02]],\n",
       "              \n",
       "                       [[-9.9032e-02,  4.8496e-02, -1.9109e-02],\n",
       "                        [-3.2291e-02, -3.0949e-02, -9.8915e-02],\n",
       "                        [ 4.3519e-02,  3.0920e-02,  5.1826e-02]],\n",
       "              \n",
       "                       [[ 1.3048e-01,  1.0944e-01, -8.5222e-02],\n",
       "                        [ 1.6681e-01,  3.7730e-02, -3.2232e-01],\n",
       "                        [-9.6782e-03,  8.1174e-02, -1.3883e-01]],\n",
       "              \n",
       "                       [[-2.1545e-03,  6.5330e-02, -1.5588e-01],\n",
       "                        [ 7.4996e-02,  6.2789e-02, -2.2556e-01],\n",
       "                        [ 5.8022e-02,  3.9025e-02, -1.0338e-01]],\n",
       "              \n",
       "                       [[-1.5090e-02, -5.9773e-02,  7.7136e-03],\n",
       "                        [ 9.5072e-02,  7.1594e-02, -6.4839e-02],\n",
       "                        [-9.6057e-02,  6.0522e-02,  3.2277e-02]],\n",
       "              \n",
       "                       [[-3.1020e-02,  3.3471e-02,  8.2861e-02],\n",
       "                        [ 4.3173e-02, -6.9619e-03, -9.6225e-03],\n",
       "                        [-2.7482e-02, -8.0584e-02,  3.6352e-02]],\n",
       "              \n",
       "                       [[-8.7997e-03, -3.6605e-03,  2.3253e-02],\n",
       "                        [ 1.0700e-01, -3.5604e-02,  8.5824e-02],\n",
       "                        [ 3.9609e-02,  9.9140e-02,  6.3725e-02]],\n",
       "              \n",
       "                       [[ 2.8321e-02,  2.2049e-01,  5.7180e-02],\n",
       "                        [ 7.6857e-02,  8.3633e-02, -2.1693e-02],\n",
       "                        [ 1.8197e-02, -1.2227e-01, -3.1078e-01]],\n",
       "              \n",
       "                       [[-8.3736e-02,  5.8932e-02,  5.7762e-02],\n",
       "                        [-5.0912e-02,  8.5033e-02, -6.7120e-03],\n",
       "                        [-1.0401e-01,  2.1023e-02,  2.5081e-02]],\n",
       "              \n",
       "                       [[ 4.3188e-02,  1.4731e-01, -1.9711e-01],\n",
       "                        [ 1.2766e-01, -8.1255e-02, -1.8791e-01],\n",
       "                        [ 7.0377e-02,  1.2465e-02, -7.9934e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5605e-01,  4.2353e-02, -5.9400e-02],\n",
       "                        [ 8.2956e-02,  2.2073e-01,  1.9501e-02],\n",
       "                        [ 8.5254e-02,  1.5736e-02, -3.0945e-02]],\n",
       "              \n",
       "                       [[-1.0353e-01, -8.2079e-02, -6.3724e-02],\n",
       "                        [-1.8504e-01,  3.5140e-02, -2.7205e-02],\n",
       "                        [-1.3200e-01,  5.6768e-02,  1.3971e-01]],\n",
       "              \n",
       "                       [[-5.2136e-02, -1.5284e-01,  1.5191e-01],\n",
       "                        [-9.9970e-02, -3.1948e-01, -4.8533e-02],\n",
       "                        [-7.0433e-02, -2.5832e-02,  1.3935e-02]],\n",
       "              \n",
       "                       [[ 2.5110e-01, -1.1280e-01, -6.3320e-02],\n",
       "                        [ 1.8239e-01, -2.4885e-01, -8.0907e-02],\n",
       "                        [ 8.7125e-02,  3.0218e-03,  4.1524e-02]],\n",
       "              \n",
       "                       [[ 8.4563e-02,  6.7453e-02, -6.5151e-02],\n",
       "                        [-2.9500e-02,  5.3895e-02, -8.1174e-02],\n",
       "                        [ 5.4610e-02, -1.2809e-01, -9.6800e-02]],\n",
       "              \n",
       "                       [[-9.5557e-02, -1.2028e-01, -4.5759e-02],\n",
       "                        [-1.5368e-01,  3.1158e-02,  3.6975e-02],\n",
       "                        [ 7.9492e-02,  7.3192e-02,  8.7144e-02]],\n",
       "              \n",
       "                       [[ 1.1592e-01,  7.5591e-02, -6.9926e-02],\n",
       "                        [ 6.6254e-02, -8.3640e-02, -1.2360e-01],\n",
       "                        [-7.5678e-02, -1.7841e-02,  3.8341e-02]],\n",
       "              \n",
       "                       [[ 2.0786e-01,  2.5379e-01,  2.7116e-01],\n",
       "                        [-1.7776e-01, -1.2214e-01,  6.9171e-02],\n",
       "                        [-5.6584e-01, -1.7133e-01, -1.8295e-01]],\n",
       "              \n",
       "                       [[ 2.3894e-02,  6.5040e-02, -1.6942e-02],\n",
       "                        [-1.5417e-02, -3.3350e-02,  9.6099e-02],\n",
       "                        [ 4.2599e-02,  7.3235e-02, -1.3027e-01]],\n",
       "              \n",
       "                       [[-1.3077e-01,  4.5670e-02,  9.1378e-02],\n",
       "                        [-8.8171e-02, -4.7480e-02,  1.6057e-02],\n",
       "                        [-8.0538e-02,  1.4942e-01,  2.5895e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3791e-02,  1.7615e-02, -1.0886e-02],\n",
       "                        [-6.5808e-02, -3.2143e-03,  1.9992e-02],\n",
       "                        [-1.4161e-02, -1.9838e-02, -1.2171e-01]],\n",
       "              \n",
       "                       [[-1.8810e-01, -1.1867e-01, -1.8127e-02],\n",
       "                        [-8.4386e-02, -3.6485e-02, -7.5354e-02],\n",
       "                        [-7.2115e-02, -4.3206e-02,  8.9849e-02]],\n",
       "              \n",
       "                       [[-4.5871e-02,  6.4057e-02, -4.2367e-03],\n",
       "                        [ 6.9964e-02,  2.1940e-01, -7.8371e-02],\n",
       "                        [ 1.8613e-01,  8.3362e-02, -1.1621e-01]],\n",
       "              \n",
       "                       [[-4.6110e-02, -6.8091e-02,  3.8344e-02],\n",
       "                        [ 7.5008e-02,  1.4906e-01,  6.0829e-02],\n",
       "                        [ 5.2173e-02,  8.1411e-02,  4.6429e-02]],\n",
       "              \n",
       "                       [[ 5.4422e-02,  5.1043e-02, -4.3092e-02],\n",
       "                        [ 1.5715e-02, -1.2150e-02,  8.5481e-02],\n",
       "                        [-6.5430e-02, -8.5989e-03,  4.8340e-03]],\n",
       "              \n",
       "                       [[ 7.5290e-02,  5.8229e-02, -1.1092e-01],\n",
       "                        [ 8.8281e-02,  7.5492e-03, -1.3078e-01],\n",
       "                        [ 2.2083e-02, -1.4718e-02,  1.1473e-02]],\n",
       "              \n",
       "                       [[ 6.5635e-02, -1.4616e-02, -7.8293e-02],\n",
       "                        [ 3.3394e-02, -3.9670e-02, -1.0726e-02],\n",
       "                        [-4.1479e-02, -8.9498e-02, -1.0247e-01]],\n",
       "              \n",
       "                       [[-3.6774e-01, -2.6212e-01, -8.6426e-02],\n",
       "                        [-4.7759e-02,  2.2323e-01,  5.5267e-02],\n",
       "                        [ 1.8005e-01,  3.2620e-01,  5.8338e-02]],\n",
       "              \n",
       "                       [[ 3.6431e-02, -4.4307e-02,  9.3267e-02],\n",
       "                        [ 4.5900e-02, -6.1573e-02,  1.2802e-02],\n",
       "                        [-9.4392e-02,  2.7522e-02,  2.3009e-02]],\n",
       "              \n",
       "                       [[ 6.3898e-02,  5.0952e-02, -8.4764e-02],\n",
       "                        [ 2.7210e-02,  1.7320e-01, -1.3684e-01],\n",
       "                        [ 1.6806e-01,  2.8759e-02,  6.6119e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8686e-01, -2.1381e-03, -9.6418e-02],\n",
       "                        [ 1.1561e-01, -3.9370e-02, -1.7266e-01],\n",
       "                        [-2.6895e-04, -1.0949e-01, -8.1901e-02]],\n",
       "              \n",
       "                       [[ 5.9127e-02,  2.0956e-01,  8.5636e-02],\n",
       "                        [ 1.7691e-02,  2.1410e-01, -9.8989e-02],\n",
       "                        [ 1.0094e-01, -2.3887e-02,  5.6969e-02]],\n",
       "              \n",
       "                       [[-2.4171e-01,  1.2382e-01, -9.2261e-02],\n",
       "                        [-1.8619e-01,  1.0125e-01,  2.6515e-02],\n",
       "                        [ 1.5953e-01,  1.4346e-01,  2.5563e-02]],\n",
       "              \n",
       "                       [[-1.7233e-01, -1.5412e-02,  1.0193e-01],\n",
       "                        [-2.1304e-01,  1.4429e-03, -2.2523e-02],\n",
       "                        [-4.5880e-02,  1.0066e-01,  1.2201e-01]],\n",
       "              \n",
       "                       [[-7.4858e-02,  5.6269e-02, -6.7420e-02],\n",
       "                        [-1.8264e-02,  9.4402e-02,  8.1227e-02],\n",
       "                        [-4.1364e-02, -4.9613e-02, -6.1664e-02]],\n",
       "              \n",
       "                       [[ 2.0933e-02, -4.2318e-02, -3.3926e-02],\n",
       "                        [ 2.6172e-02,  4.0313e-02, -5.7732e-02],\n",
       "                        [ 1.3326e-01,  4.1682e-02,  5.1592e-02]],\n",
       "              \n",
       "                       [[-1.6574e-02, -4.6067e-02,  8.9183e-03],\n",
       "                        [-6.2420e-02,  7.0338e-02, -1.5841e-02],\n",
       "                        [-6.7276e-02,  2.4373e-03,  4.8621e-02]],\n",
       "              \n",
       "                       [[ 2.8191e-01,  1.7331e-01, -2.7966e-02],\n",
       "                        [-5.5188e-02, -7.5055e-02, -1.1903e-01],\n",
       "                        [-2.2799e-02, -1.4888e-01, -2.2160e-02]],\n",
       "              \n",
       "                       [[ 2.8379e-02,  1.2070e-02,  1.0044e-01],\n",
       "                        [-5.5228e-02, -1.0489e-01, -4.7343e-02],\n",
       "                        [-1.1246e-01, -1.1436e-02, -5.4899e-02]],\n",
       "              \n",
       "                       [[-2.4059e-01, -2.9104e-02, -5.7425e-02],\n",
       "                        [-3.6560e-02,  6.8684e-02, -1.7293e-02],\n",
       "                        [ 1.9784e-01,  1.6957e-01,  9.6507e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.2117e-02,  1.1499e-01, -1.9729e-01],\n",
       "                        [-4.6943e-02, -6.5688e-02, -1.2318e-01],\n",
       "                        [-1.9471e-02, -3.1327e-02, -1.1824e-01]],\n",
       "              \n",
       "                       [[ 1.2579e-01,  2.7944e-02, -8.1655e-03],\n",
       "                        [-5.0946e-03,  6.5965e-02, -4.2056e-02],\n",
       "                        [-9.1507e-04, -3.6496e-02, -8.0303e-02]],\n",
       "              \n",
       "                       [[-6.8619e-03,  1.5733e-01,  7.0479e-02],\n",
       "                        [ 8.1961e-02,  3.5372e-01,  1.4069e-01],\n",
       "                        [-1.3981e-01, -1.0843e-01,  2.3542e-02]],\n",
       "              \n",
       "                       [[-4.2711e-02,  9.2552e-02, -4.0222e-02],\n",
       "                        [-1.2021e-01,  1.1325e-01,  2.0532e-01],\n",
       "                        [ 9.5497e-02, -3.5706e-02, -6.3904e-02]],\n",
       "              \n",
       "                       [[-4.0642e-03, -2.9030e-02,  5.3212e-02],\n",
       "                        [-2.0535e-02, -1.5210e-02,  5.1011e-02],\n",
       "                        [ 9.7415e-03, -7.1738e-03, -3.9041e-02]],\n",
       "              \n",
       "                       [[-4.3638e-02, -6.4352e-02,  2.8823e-03],\n",
       "                        [ 4.1060e-02, -3.3224e-02,  2.7360e-02],\n",
       "                        [-7.6709e-02,  3.4532e-02,  4.3280e-02]],\n",
       "              \n",
       "                       [[-2.0137e-02, -5.6389e-02, -1.0359e-01],\n",
       "                        [-1.6748e-02, -3.8060e-02,  8.0078e-02],\n",
       "                        [ 2.6896e-02,  4.9925e-02,  6.7212e-02]],\n",
       "              \n",
       "                       [[-1.0711e-01, -1.5394e-01, -3.8490e-01],\n",
       "                        [-1.5029e-02,  2.5369e-01,  2.2885e-02],\n",
       "                        [-6.6301e-02,  1.7676e-01,  2.5136e-01]],\n",
       "              \n",
       "                       [[-5.1225e-02, -6.0326e-02,  9.8946e-02],\n",
       "                        [ 7.6337e-02, -3.3930e-02, -6.9759e-02],\n",
       "                        [ 1.0174e-01, -7.8648e-02,  2.1631e-02]],\n",
       "              \n",
       "                       [[ 5.0903e-02,  2.3974e-01, -1.0411e-01],\n",
       "                        [ 4.2567e-02,  2.9190e-01, -7.8465e-02],\n",
       "                        [-1.9608e-01, -7.8289e-02,  7.5918e-02]]]])),\n",
       "             ('conv_block_2.0.bias',\n",
       "              tensor([-0.0117, -0.1636,  0.0660, -0.1132,  0.0326,  0.1771,  0.1360, -0.0652,\n",
       "                       0.0974, -0.0306])),\n",
       "             ('conv_block_2.2.weight',\n",
       "              tensor([[[[ 9.1007e-02,  9.4971e-02,  1.0329e-01],\n",
       "                        [ 4.6911e-02,  3.1559e-02, -3.4052e-02],\n",
       "                        [-3.6937e-02,  4.7341e-02, -4.6438e-02]],\n",
       "              \n",
       "                       [[-1.7698e-01,  1.0587e-01, -1.7983e-02],\n",
       "                        [-7.7163e-02,  2.4790e-02,  4.6833e-02],\n",
       "                        [-1.3107e-01, -1.2173e-01, -8.3447e-02]],\n",
       "              \n",
       "                       [[-7.7372e-02, -1.9213e-02, -9.8496e-02],\n",
       "                        [ 3.7259e-02,  6.8121e-02,  1.0507e-02],\n",
       "                        [-1.8383e-02, -1.0846e-01,  6.4243e-02]],\n",
       "              \n",
       "                       [[ 5.6169e-02,  5.6011e-02, -4.3695e-02],\n",
       "                        [ 1.6511e-01,  9.9671e-02, -3.3686e-02],\n",
       "                        [ 9.4226e-02,  1.4083e-01,  1.1342e-02]],\n",
       "              \n",
       "                       [[ 1.8944e-03, -1.3463e-01, -1.2670e-01],\n",
       "                        [ 1.7838e-02, -1.2707e-01, -6.8656e-02],\n",
       "                        [-2.2667e-02, -7.2823e-02, -1.0771e-01]],\n",
       "              \n",
       "                       [[-1.0036e-01, -1.0894e-02, -3.7270e-03],\n",
       "                        [ 1.6011e-02, -3.8667e-02, -1.0448e-01],\n",
       "                        [ 4.9816e-02, -2.6597e-01,  4.0837e-02]],\n",
       "              \n",
       "                       [[-1.0106e-01, -2.3287e-01, -1.4046e-01],\n",
       "                        [-7.4179e-02, -2.4274e-01, -1.2475e-01],\n",
       "                        [-9.0136e-02, -8.4467e-02, -2.7440e-01]],\n",
       "              \n",
       "                       [[ 6.1149e-03,  1.1969e-02,  6.9124e-02],\n",
       "                        [-4.4107e-02,  3.8476e-02,  5.3587e-02],\n",
       "                        [-6.1748e-02, -1.7237e-02, -6.9040e-02]],\n",
       "              \n",
       "                       [[-1.1487e-01,  1.1138e-02,  8.7270e-03],\n",
       "                        [-2.6211e-02,  8.6732e-03, -9.4610e-02],\n",
       "                        [-5.0268e-02,  4.9247e-02,  2.2620e-02]],\n",
       "              \n",
       "                       [[ 2.6155e-02,  1.1279e-01,  2.6330e-02],\n",
       "                        [-2.2743e-01,  9.7394e-02,  8.9729e-02],\n",
       "                        [-2.1066e-01, -1.3946e-01,  8.0156e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.0769e-02,  6.2270e-02, -9.0967e-02],\n",
       "                        [-1.2771e-02,  9.7065e-02, -3.2629e-02],\n",
       "                        [ 3.9067e-03, -5.5872e-02,  1.9561e-03]],\n",
       "              \n",
       "                       [[-9.3530e-02, -2.9705e-01, -1.6779e-01],\n",
       "                        [ 1.5076e-01, -7.3708e-02, -1.9661e-01],\n",
       "                        [-4.5748e-02, -2.1605e-01, -2.4216e-02]],\n",
       "              \n",
       "                       [[ 3.3328e-03,  8.2748e-02, -2.4980e-02],\n",
       "                        [-1.5581e-02, -1.6173e-03, -1.5339e-01],\n",
       "                        [-3.0587e-02,  1.2625e-01, -6.4359e-02]],\n",
       "              \n",
       "                       [[ 4.3779e-02,  2.8492e-02,  4.3475e-02],\n",
       "                        [-5.3009e-02, -1.2318e-01,  6.2242e-02],\n",
       "                        [-1.0889e-01,  2.7715e-02, -9.9247e-02]],\n",
       "              \n",
       "                       [[-4.8541e-02,  7.0980e-02,  2.4153e-02],\n",
       "                        [ 1.3819e-02, -6.5742e-02,  1.6617e-02],\n",
       "                        [-6.3479e-02,  1.6825e-02,  4.1671e-02]],\n",
       "              \n",
       "                       [[ 7.4811e-02,  4.4999e-02, -1.4329e-01],\n",
       "                        [ 1.1408e-01,  9.0790e-02, -1.8675e-01],\n",
       "                        [ 2.3971e-02, -1.6711e-02, -3.1207e-01]],\n",
       "              \n",
       "                       [[-2.7156e-01, -7.6241e-02,  1.0047e-01],\n",
       "                        [-9.4968e-02, -4.1052e-02,  1.0633e-01],\n",
       "                        [ 5.1169e-02,  1.4730e-01,  1.3987e-01]],\n",
       "              \n",
       "                       [[ 1.0794e-01, -2.2253e-01, -1.6946e-01],\n",
       "                        [-1.4983e-01, -1.4057e-01, -1.7479e-01],\n",
       "                        [-2.3787e-01, -1.3425e-01, -3.4770e-01]],\n",
       "              \n",
       "                       [[-2.9494e-02, -1.2735e-01, -5.0043e-02],\n",
       "                        [-1.1416e-01, -9.6939e-02,  1.0442e-01],\n",
       "                        [-3.3693e-03,  2.5786e-02,  1.4810e-01]],\n",
       "              \n",
       "                       [[ 1.5519e-01, -2.9261e-01, -1.4331e-01],\n",
       "                        [-1.0901e-01, -2.2574e-01, -9.2028e-02],\n",
       "                        [-2.6586e-01, -2.3972e-01,  7.3978e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.5974e-02,  1.9752e-02,  7.7258e-02],\n",
       "                        [-4.3799e-02, -2.8697e-02, -4.6450e-02],\n",
       "                        [ 7.7858e-02, -7.4195e-02, -1.2851e-02]],\n",
       "              \n",
       "                       [[-8.3585e-02, -5.2442e-02, -2.7677e-03],\n",
       "                        [-2.5990e-01, -1.8974e-01, -1.3506e-01],\n",
       "                        [-2.4002e-01, -3.8805e-01, -1.0983e-01]],\n",
       "              \n",
       "                       [[-4.1918e-02, -1.6473e-01,  5.0508e-02],\n",
       "                        [-9.7513e-02, -4.2788e-02, -9.1300e-02],\n",
       "                        [ 1.0987e-01, -3.6098e-03, -2.9519e-02]],\n",
       "              \n",
       "                       [[-6.1002e-02,  1.1665e-01, -9.7015e-02],\n",
       "                        [ 3.6283e-02,  7.7652e-02, -1.2405e-01],\n",
       "                        [ 4.1115e-03,  1.4076e-01, -4.0365e-02]],\n",
       "              \n",
       "                       [[-1.6428e-01,  1.1087e-02, -1.5637e-01],\n",
       "                        [-3.5572e-02,  8.2579e-02, -1.8417e-01],\n",
       "                        [ 2.2921e-02,  9.6472e-02, -1.9443e-02]],\n",
       "              \n",
       "                       [[-7.8260e-03, -1.6530e-01,  8.8743e-02],\n",
       "                        [-2.4057e-01, -4.8066e-01,  2.5774e-01],\n",
       "                        [-3.2688e-01, -3.2733e-01,  1.7419e-01]],\n",
       "              \n",
       "                       [[ 8.2593e-02, -1.6509e-01, -3.1495e-01],\n",
       "                        [ 1.7040e-01, -1.4849e-01, -3.8466e-01],\n",
       "                        [ 4.6510e-02, -1.3150e-02, -3.8918e-01]],\n",
       "              \n",
       "                       [[-2.8580e-01, -7.0629e-02,  1.0930e-02],\n",
       "                        [-3.2190e-01, -2.2232e-01,  6.9825e-02],\n",
       "                        [-1.4602e-01, -9.0520e-02,  2.2482e-02]],\n",
       "              \n",
       "                       [[-9.8061e-02, -7.9760e-03, -1.5252e-01],\n",
       "                        [ 1.6309e-02,  1.3983e-01, -6.5797e-02],\n",
       "                        [-2.3702e-02,  3.1471e-01,  1.3917e-01]],\n",
       "              \n",
       "                       [[-1.1622e-01, -2.6132e-02,  6.9458e-02],\n",
       "                        [-8.8275e-02,  5.8918e-03, -4.9905e-02],\n",
       "                        [-3.3888e-01,  3.8997e-02, -1.4717e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.3374e-02,  5.8557e-02,  8.1842e-02],\n",
       "                        [-7.1533e-02,  5.4119e-02, -3.7636e-02],\n",
       "                        [-2.8785e-03,  1.4273e-02, -9.4090e-02]],\n",
       "              \n",
       "                       [[-7.8690e-03,  5.9270e-02, -8.1395e-03],\n",
       "                        [-9.3429e-02,  3.0273e-02,  1.8546e-02],\n",
       "                        [-7.9896e-02, -2.2160e-03, -6.0149e-02]],\n",
       "              \n",
       "                       [[-9.3251e-02, -8.0907e-02, -6.3842e-02],\n",
       "                        [ 6.8244e-02,  7.7017e-02,  8.4548e-02],\n",
       "                        [-7.2160e-02,  4.1538e-02, -1.1400e-01]],\n",
       "              \n",
       "                       [[-1.3929e-01, -8.7866e-02, -4.3810e-02],\n",
       "                        [ 4.3930e-02, -5.2314e-02,  7.7041e-02],\n",
       "                        [ 5.9972e-02, -4.7914e-02, -8.7536e-05]],\n",
       "              \n",
       "                       [[-9.8647e-02,  5.7498e-02,  8.1070e-02],\n",
       "                        [-6.7173e-02,  3.9022e-02, -1.9803e-02],\n",
       "                        [-7.7019e-02,  9.3348e-02, -2.4038e-02]],\n",
       "              \n",
       "                       [[-1.1747e-02,  2.8476e-02, -3.3707e-02],\n",
       "                        [ 1.4232e-03,  1.5054e-02, -3.8762e-02],\n",
       "                        [-3.8958e-02,  2.1221e-02, -3.0238e-02]],\n",
       "              \n",
       "                       [[-1.1383e-01,  9.9179e-03, -1.0533e-01],\n",
       "                        [-1.7063e-01, -1.3758e-01, -8.6199e-02],\n",
       "                        [-1.1353e-02, -9.6924e-02,  2.7892e-03]],\n",
       "              \n",
       "                       [[-7.8811e-02, -4.2636e-02, -5.6427e-02],\n",
       "                        [-8.5210e-02,  1.1613e-02,  1.0181e-02],\n",
       "                        [-1.0977e-02,  3.3874e-02,  3.9594e-02]],\n",
       "              \n",
       "                       [[-6.6149e-02,  2.0968e-02,  4.6175e-02],\n",
       "                        [-2.3059e-02, -5.7747e-02,  1.1675e-02],\n",
       "                        [-8.5102e-02, -9.6585e-02, -1.6551e-02]],\n",
       "              \n",
       "                       [[ 8.9819e-03, -7.6186e-02, -1.0287e-01],\n",
       "                        [-8.7757e-02, -1.1563e-01,  1.4026e-02],\n",
       "                        [-1.0687e-01, -9.0704e-02, -1.0425e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1612e-02,  4.4937e-04,  2.7229e-02],\n",
       "                        [ 7.3821e-02, -8.2169e-02, -2.4154e-02],\n",
       "                        [-6.2192e-02, -3.7007e-02,  3.5163e-02]],\n",
       "              \n",
       "                       [[-1.1401e-02, -1.1672e-01, -2.0746e-02],\n",
       "                        [ 5.7810e-02, -1.2476e-01, -3.5658e-02],\n",
       "                        [-3.4506e-02,  6.7194e-03, -3.1959e-02]],\n",
       "              \n",
       "                       [[ 5.1238e-02,  1.0505e-01, -6.4263e-02],\n",
       "                        [-1.1184e-01,  5.8088e-02, -6.0811e-02],\n",
       "                        [ 5.4121e-02, -2.3200e-02, -7.8318e-03]],\n",
       "              \n",
       "                       [[ 3.0981e-02, -1.0060e-01, -3.6988e-02],\n",
       "                        [ 1.0360e-01,  5.8961e-02,  8.5530e-02],\n",
       "                        [-7.6643e-02, -5.3814e-02, -8.2159e-02]],\n",
       "              \n",
       "                       [[-2.5820e-02,  2.1290e-03,  2.2352e-02],\n",
       "                        [-2.2595e-03,  8.9760e-02, -6.1996e-02],\n",
       "                        [-1.0850e-01,  4.2802e-02, -5.5007e-02]],\n",
       "              \n",
       "                       [[ 5.6508e-02, -8.1123e-02, -1.0563e-02],\n",
       "                        [ 5.0771e-03, -5.8653e-02, -4.6777e-02],\n",
       "                        [-8.4110e-03, -1.0153e-01,  4.2036e-02]],\n",
       "              \n",
       "                       [[-5.1136e-02, -1.4878e-02, -6.4811e-02],\n",
       "                        [-8.7819e-02, -3.2210e-02,  6.9374e-02],\n",
       "                        [-7.4530e-02, -5.2277e-02,  5.6769e-02]],\n",
       "              \n",
       "                       [[ 2.5885e-02,  8.9155e-02, -4.0455e-02],\n",
       "                        [-6.8764e-02, -4.8836e-02,  5.4902e-02],\n",
       "                        [-5.1598e-02, -8.5843e-02, -1.2105e-01]],\n",
       "              \n",
       "                       [[ 1.0996e-02,  4.4353e-02, -1.2391e-01],\n",
       "                        [ 7.5703e-02, -7.2134e-02, -1.1673e-02],\n",
       "                        [ 4.3528e-02, -1.0639e-01,  4.7207e-03]],\n",
       "              \n",
       "                       [[-1.3090e-01,  1.8538e-03, -1.2689e-01],\n",
       "                        [ 1.4521e-02, -3.9643e-02, -3.9552e-02],\n",
       "                        [-8.6446e-02,  4.9483e-02,  4.2328e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.6911e-02, -7.3579e-02,  2.0873e-02],\n",
       "                        [-1.3977e-02,  5.5502e-02, -1.1655e-03],\n",
       "                        [-3.5165e-03,  4.4102e-02, -8.5821e-02]],\n",
       "              \n",
       "                       [[-1.8506e-01,  1.2830e-01,  2.2550e-01],\n",
       "                        [-1.6404e-01, -4.4824e-02,  4.6653e-02],\n",
       "                        [-1.1880e-01, -4.0743e-02, -2.8926e-01]],\n",
       "              \n",
       "                       [[-1.0317e-01, -3.8456e-01, -2.2148e-01],\n",
       "                        [-8.7738e-02, -3.6896e-01, -1.4500e-01],\n",
       "                        [-6.0941e-02, -9.4528e-02, -2.0389e-01]],\n",
       "              \n",
       "                       [[ 7.2966e-02, -5.1927e-02,  9.3340e-02],\n",
       "                        [-3.2140e-03, -5.7858e-02, -3.2713e-02],\n",
       "                        [ 1.0180e-01, -2.5816e-02, -6.3781e-02]],\n",
       "              \n",
       "                       [[-4.0974e-02,  1.2630e-01, -1.2444e-02],\n",
       "                        [ 9.9627e-02, -1.7799e-01, -1.1672e-01],\n",
       "                        [-9.9075e-03, -9.9084e-02, -9.3801e-02]],\n",
       "              \n",
       "                       [[ 5.0800e-03,  8.6107e-02, -3.6426e-02],\n",
       "                        [-8.5891e-02, -1.7075e-02,  1.4832e-01],\n",
       "                        [-2.5084e-01, -1.2090e-01, -5.0577e-02]],\n",
       "              \n",
       "                       [[-1.7609e-01, -1.9337e-01, -2.9405e-01],\n",
       "                        [ 5.3968e-02,  1.2283e-01, -1.1636e-01],\n",
       "                        [ 1.8161e-01,  1.0473e-01,  8.1221e-02]],\n",
       "              \n",
       "                       [[-2.4210e-01, -1.2287e-01,  1.9372e-01],\n",
       "                        [-2.8656e-01, -2.8125e-01,  1.3151e-01],\n",
       "                        [-1.3126e-01, -1.3569e-01,  3.9015e-03]],\n",
       "              \n",
       "                       [[-3.6326e-02, -1.0272e-01, -2.7276e-02],\n",
       "                        [-2.3004e-01, -9.7422e-03, -1.4199e-02],\n",
       "                        [ 1.8112e-01, -5.7791e-02,  7.3426e-02]],\n",
       "              \n",
       "                       [[-1.4140e-01,  8.7595e-02,  1.4784e-01],\n",
       "                        [-3.3416e-01, -1.0415e-01,  1.1969e-01],\n",
       "                        [-9.8877e-02, -2.3912e-01,  6.8417e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0030e-02,  9.3705e-02,  3.4328e-02],\n",
       "                        [ 4.2475e-02,  7.2875e-02, -2.1917e-02],\n",
       "                        [-5.9745e-02, -4.6784e-02,  2.6468e-02]],\n",
       "              \n",
       "                       [[ 5.3907e-02,  5.7515e-02,  3.1487e-03],\n",
       "                        [ 3.2660e-02,  1.0833e-01, -9.7142e-02],\n",
       "                        [-1.8901e-02, -3.4352e-02, -5.8043e-02]],\n",
       "              \n",
       "                       [[ 7.8656e-02, -5.8456e-02, -5.9686e-02],\n",
       "                        [ 7.2405e-02,  1.5017e-02, -7.8967e-03],\n",
       "                        [-5.2926e-02,  4.8332e-02,  2.7479e-03]],\n",
       "              \n",
       "                       [[ 3.0745e-02,  9.0610e-02, -3.8322e-02],\n",
       "                        [ 8.5155e-02, -3.4856e-03, -8.7242e-02],\n",
       "                        [-6.4388e-02, -7.0762e-02,  1.6667e-03]],\n",
       "              \n",
       "                       [[ 9.1900e-02,  1.1290e-01,  2.0780e-02],\n",
       "                        [-1.7821e-02,  1.1377e-01, -5.0659e-02],\n",
       "                        [ 1.3581e-01, -1.4414e-02, -6.9753e-02]],\n",
       "              \n",
       "                       [[-5.6986e-02, -6.8660e-02,  6.7972e-02],\n",
       "                        [ 1.0071e-01, -6.9398e-02, -9.1877e-02],\n",
       "                        [ 3.1902e-02, -5.4390e-02, -3.2953e-02]],\n",
       "              \n",
       "                       [[-6.0719e-02, -1.0344e-03,  1.4731e-02],\n",
       "                        [-4.6219e-02, -1.1325e-01, -5.1371e-02],\n",
       "                        [-3.8026e-02,  7.0135e-03,  7.0663e-02]],\n",
       "              \n",
       "                       [[-3.8706e-03, -1.0649e-01,  8.7970e-02],\n",
       "                        [-9.0016e-02, -9.1617e-02, -4.0355e-02],\n",
       "                        [-2.4421e-02, -5.0582e-02,  1.0350e-02]],\n",
       "              \n",
       "                       [[-1.0170e-01,  2.4739e-02, -2.9920e-02],\n",
       "                        [ 2.0451e-02, -9.7470e-02, -1.3227e-02],\n",
       "                        [-1.4364e-01,  8.2506e-03, -5.5130e-02]],\n",
       "              \n",
       "                       [[-4.6914e-02,  1.8552e-02, -1.2173e-01],\n",
       "                        [ 1.0527e-02, -1.0199e-01, -1.0978e-01],\n",
       "                        [-1.1997e-01, -7.6396e-02,  7.3609e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.5928e-02,  3.4352e-02,  1.7239e-02],\n",
       "                        [ 1.0305e-02,  1.0426e-01, -6.4446e-02],\n",
       "                        [ 6.4912e-03,  4.2138e-03,  9.9600e-02]],\n",
       "              \n",
       "                       [[-3.4849e-02, -2.8072e-02, -9.8588e-02],\n",
       "                        [-1.1998e-01, -9.2828e-02, -3.3500e-02],\n",
       "                        [-1.1039e-01,  4.1214e-02,  5.6225e-02]],\n",
       "              \n",
       "                       [[ 2.6364e-02, -1.0142e-01, -4.6625e-02],\n",
       "                        [-1.6304e-02, -1.0126e-01, -4.8658e-02],\n",
       "                        [-2.5894e-02,  3.7955e-02,  1.9902e-02]],\n",
       "              \n",
       "                       [[ 1.2752e-02,  8.6095e-02, -5.0805e-02],\n",
       "                        [ 8.6143e-02,  2.8411e-02, -5.4660e-02],\n",
       "                        [ 8.0094e-02,  1.0365e-01,  4.4719e-02]],\n",
       "              \n",
       "                       [[-4.5706e-02, -6.4990e-02,  1.7232e-02],\n",
       "                        [ 9.6701e-02, -3.3692e-02, -2.3498e-02],\n",
       "                        [-5.6836e-02,  8.8346e-03,  5.8635e-02]],\n",
       "              \n",
       "                       [[-2.5384e-02, -2.3740e-02,  9.3683e-03],\n",
       "                        [-1.6527e-01,  8.0101e-02,  6.6070e-02],\n",
       "                        [ 6.5290e-04, -9.6536e-02, -4.7612e-03]],\n",
       "              \n",
       "                       [[-1.0417e-01,  8.2158e-02,  2.9128e-02],\n",
       "                        [-2.8465e-02, -7.0507e-02, -3.9003e-02],\n",
       "                        [-6.0710e-02, -3.3419e-02,  9.5839e-03]],\n",
       "              \n",
       "                       [[-5.5346e-02, -8.2239e-02, -1.3538e-03],\n",
       "                        [-8.3794e-02,  9.3782e-03, -5.1790e-02],\n",
       "                        [ 3.7931e-02, -2.3876e-02, -1.2495e-02]],\n",
       "              \n",
       "                       [[-7.0958e-02,  6.6177e-03, -3.7214e-03],\n",
       "                        [ 9.8405e-04, -4.7148e-02,  3.9624e-02],\n",
       "                        [ 3.5538e-02, -4.4717e-03,  1.6902e-02]],\n",
       "              \n",
       "                       [[-9.4809e-03,  1.5645e-02, -1.2264e-01],\n",
       "                        [-1.0251e-01,  4.5000e-03, -6.2739e-02],\n",
       "                        [-1.0312e-01, -1.6362e-01, -1.1640e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0208e-01, -8.2968e-02,  5.8343e-02],\n",
       "                        [ 1.4618e-02,  9.5616e-02,  1.5667e-02],\n",
       "                        [-8.6816e-02, -4.8908e-03,  1.7051e-02]],\n",
       "              \n",
       "                       [[-2.6822e-03, -1.0540e-01, -1.4303e-02],\n",
       "                        [-5.4379e-02, -1.1041e-01,  5.9474e-02],\n",
       "                        [ 2.7087e-02,  2.6202e-02, -1.0624e-01]],\n",
       "              \n",
       "                       [[-3.4062e-02, -2.9183e-02,  1.9106e-02],\n",
       "                        [ 2.0716e-02, -8.2732e-02,  9.2396e-02],\n",
       "                        [ 5.0796e-03, -1.0538e-01,  4.0956e-03]],\n",
       "              \n",
       "                       [[ 6.3626e-02,  5.3945e-02, -8.4435e-02],\n",
       "                        [ 8.8186e-02, -1.9742e-02,  5.4228e-02],\n",
       "                        [-4.5337e-02, -3.1619e-02,  3.7857e-02]],\n",
       "              \n",
       "                       [[ 3.5107e-02, -9.4313e-02,  3.2482e-02],\n",
       "                        [ 6.5763e-02,  6.7007e-02, -5.8462e-02],\n",
       "                        [-8.3006e-02, -2.3906e-02, -1.8470e-02]],\n",
       "              \n",
       "                       [[-5.0473e-02,  3.1262e-02,  5.1135e-03],\n",
       "                        [-6.3554e-02, -4.4499e-02, -2.4308e-02],\n",
       "                        [ 1.3603e-04, -6.3261e-02, -1.1270e-01]],\n",
       "              \n",
       "                       [[-8.1960e-02,  3.0418e-02, -3.0516e-02],\n",
       "                        [-3.4208e-02,  3.6842e-02,  2.8377e-02],\n",
       "                        [-8.3053e-02, -9.4377e-02,  2.5947e-02]],\n",
       "              \n",
       "                       [[-2.1880e-04, -4.4151e-04,  5.1350e-02],\n",
       "                        [-1.6024e-02,  4.5119e-03, -1.2426e-01],\n",
       "                        [-3.4266e-02, -8.6337e-02, -1.2080e-02]],\n",
       "              \n",
       "                       [[-7.6013e-02, -1.1361e-01, -9.1633e-02],\n",
       "                        [-5.7559e-02, -1.0290e-01,  2.4537e-02],\n",
       "                        [ 2.6131e-02, -1.4576e-01,  6.6907e-03]],\n",
       "              \n",
       "                       [[-6.8905e-02, -6.5575e-03, -1.3041e-01],\n",
       "                        [ 3.0169e-02, -1.2927e-01, -1.0633e-02],\n",
       "                        [-2.9780e-02,  3.2493e-02,  2.6038e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2292e-02, -1.0424e-01, -1.0001e-01],\n",
       "                        [-8.3145e-02, -3.5029e-02,  9.0765e-02],\n",
       "                        [-5.1802e-02, -1.0581e-01,  4.0532e-02]],\n",
       "              \n",
       "                       [[-1.7485e-01,  7.7810e-02, -1.6378e-02],\n",
       "                        [ 3.7493e-02, -1.4548e-01,  4.5940e-02],\n",
       "                        [-1.1625e-01, -8.4091e-02, -1.0880e-01]],\n",
       "              \n",
       "                       [[ 6.6461e-02, -1.6703e-02, -4.3509e-02],\n",
       "                        [-2.7336e-02, -8.4852e-02,  6.3884e-02],\n",
       "                        [-1.1516e-01, -1.6399e-01, -7.7627e-02]],\n",
       "              \n",
       "                       [[ 2.2464e-02,  2.9861e-03, -8.0248e-02],\n",
       "                        [-3.8618e-03,  3.8691e-02,  8.1134e-02],\n",
       "                        [-6.9691e-02, -9.6343e-03, -2.5883e-02]],\n",
       "              \n",
       "                       [[ 1.8435e-03, -4.3979e-02,  3.8793e-02],\n",
       "                        [ 3.4959e-02,  1.0665e-01, -7.4885e-02],\n",
       "                        [-6.7258e-03,  1.1622e-01,  1.7577e-01]],\n",
       "              \n",
       "                       [[-2.7170e-01, -1.2837e-01,  2.3040e-01],\n",
       "                        [-6.4654e-02,  9.4321e-02,  8.4642e-02],\n",
       "                        [ 1.1067e-01, -3.9440e-02, -1.4176e-01]],\n",
       "              \n",
       "                       [[-2.9121e-01, -9.8829e-02, -3.3835e-01],\n",
       "                        [-8.1498e-02, -8.5261e-02, -1.5821e-01],\n",
       "                        [ 1.1902e-01, -6.5303e-02, -1.5316e-01]],\n",
       "              \n",
       "                       [[ 1.6262e-01,  1.6320e-01,  1.5803e-01],\n",
       "                        [ 2.6451e-02, -7.6293e-02, -2.3174e-01],\n",
       "                        [-6.7100e-02, -2.4213e-01, -3.0062e-01]],\n",
       "              \n",
       "                       [[-1.1000e-01,  6.5435e-02, -1.1535e-01],\n",
       "                        [-4.4039e-02, -1.0494e-01, -9.8514e-02],\n",
       "                        [-2.4961e-01,  2.1322e-01,  1.1809e-01]],\n",
       "              \n",
       "                       [[ 1.1720e-01,  1.6297e-01, -5.3875e-03],\n",
       "                        [ 2.6780e-02,  1.3104e-01, -8.6014e-02],\n",
       "                        [-3.2063e-01, -3.4724e-01, -1.7334e-01]]]])),\n",
       "             ('conv_block_2.2.bias',\n",
       "              tensor([-0.0450,  0.0330,  0.1467, -0.0124, -0.0913, -0.0664, -0.1061, -0.1233,\n",
       "                      -0.0629,  0.0934])),\n",
       "             ('classifier.1.weight',\n",
       "              tensor([[ 0.0173,  0.0210,  0.0385,  ..., -0.0257,  0.0712,  0.0422],\n",
       "                      [-0.0284, -0.0264, -0.0398,  ...,  0.0251, -0.0720, -0.0377]])),\n",
       "             ('classifier.1.bias', tensor([ 0.2223, -0.2282]))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bec84603-8f65-4502-a14e-02cfa9f08f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyVGG(\n",
       "  (conv_block_1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=28090, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae73f73d-6229-4167-8377-11118a21e700",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (DataLoader, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mDataLoader\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple of (int, int)\u001b[0m, \u001b[31;1mtuple of (int, int)\u001b[0m, \u001b[31;1mtuple of (int, int)\u001b[0m, \u001b[32;1mint\u001b[0m)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mDataLoader\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple of (int, int)\u001b[0m, \u001b[31;1mtuple of (int, int)\u001b[0m, \u001b[31;1mtuple of (int, int)\u001b[0m, \u001b[32;1mint\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-184ae35df7e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mloaded_model_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1517\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1518\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-6a945a22bacb>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_block_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;31m# print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_block_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1517\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1518\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1517\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1518\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 456\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (DataLoader, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mDataLoader\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple of (int, int)\u001b[0m, \u001b[31;1mtuple of (int, int)\u001b[0m, \u001b[31;1mtuple of (int, int)\u001b[0m, \u001b[32;1mint\u001b[0m)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mDataLoader\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple of (int, int)\u001b[0m, \u001b[31;1mtuple of (int, int)\u001b[0m, \u001b[31;1mtuple of (int, int)\u001b[0m, \u001b[32;1mint\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    loaded_model_preds = model(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8620d2f0-b3c0-4a14-9b3b-dd7c630b65bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
